{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52359b17-1216-4744-a528-81e23a033a68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Project Cars4you (Group 5): Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cars 4 You is an online car resale company that sells cars from multiple different brands.  \n",
    "Their main goal is to expedite the evaluation process by creating a predictive model capable of evaluating the price of a car based on the user’s input without needing the car to be taken to a mechanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Attribute**       | **Description** |\n",
    "|----------------------|-----------------|\n",
    "| **carID**            | An attribute that contains an identifier for each car. |\n",
    "| **Brand**            | The car’s main brand (e.g. Ford, Toyota) |\n",
    "| **model**            | The car model |\n",
    "| **year**             | The year of Registration of the Car |\n",
    "| **mileage**          | The total reported distance travelled by the car (in miles) |\n",
    "| **tax**              | The amount of road tax (in £) that, in 2020, was applicable to the car in question. |\n",
    "| **fuelType**         | Type of Fuel used by the car (Diesel, Petrol, Hybrid, Electric) |\n",
    "| **mpg**              | Average Miles per Gallon (fuel efficiency) |\n",
    "| **engineSize**       | Size of engine in liters (cubic decimeters) |\n",
    "| **paintQuality%**    | The mechanic’s assessment of the cars’ overall paint quality and hull integrity (filled by the mechanic during evaluation). |\n",
    "| **previousOwners**   | Number of previous registered owners of the vehicle |\n",
    "| **hasDamage**        | Boolean marker filled by the seller at the time of registration stating whether the car is damaged or not |\n",
    "| **price (TARGET)**            | The car’s price when purchased by Cars 4 You (in £) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b65f0ae-0d7a-4cdb-830a-391a209b82d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "TASK I (3 Points): Descriptive Statistics, Inconsistency Check, Visual Data Explorance, Extraction of Relevant Insights, Multivariate Relationships  => Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27fff3e4-624f-4b1f-b258-fbbe7b69cb00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1. Import & load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f54ab11e-fcfc-4278-8997-89a92adf8eff",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import and load Data"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "from data_cleaning import clean_car_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train = pd.read_csv(\"train.csv\")\n",
    "df_cars_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basic Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "00193525-37c5-4d69-bc00-605d8fb49f7d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Decriptive Statistics"
    }
   },
   "outputs": [],
   "source": [
    "# Overview of structure and data types\n",
    "df_cars_train.info()\n",
    "\n",
    "# Strip whitespace and lowercase before duplicate check\n",
    "df_cars_train = df_cars_train.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate rows: {df_cars_train.duplicated().sum()}\") # 0\n",
    "\n",
    "# Check for duplicate carID\n",
    "print(f\"\\nDuplicate carID: {df_cars_train['carID'].duplicated().sum()}\") # 0\n",
    "print(f\"Null values in column carID: {df_cars_train['carID'].isnull().sum()}\") # 0\n",
    "print(f\"All carID entries are unique: {df_cars_train['carID'].nunique()}/{len(df_cars_train)}\")\n",
    "\n",
    "\n",
    "# Findings:\n",
    "#   - missing values in every column except carID and price\n",
    "#   - year, mpg, previousOwners, hasDamage as float seems weird\n",
    "#   - no duplicates in all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_cars_train.describe().T)\n",
    "display(df_cars_train.describe(include=\"object\").T)\n",
    "\n",
    "### First Findings (extensive description of each attribute in Univariate Section):\n",
    "# Numerical:\n",
    "#   - carID is unique identifier\n",
    "#   - years range from 1970 to 2024.12 (a float so maybe some have month info?) with most of the cars being between 2016 and 2019 (max value of 2024 doesnt make sense because database is from 2020)\n",
    "#   - price ranges from 450 to 159.999 with mean ~17.000, median ~14.500 and std ~10.000 -> right skewed distribution (some cars with high prices)\n",
    "#   - mileage ranges from a negative value (probably wrong data entry) to 323.000 with mean ~23.000, median 17300 and std ~22.000 -> right skewed distribution (some cars with very high mileage) and high variance\n",
    "#   - tax ranges from a negative value (probably wrong data entry) to 580 with mean ~120, median 145 and std ~65 -> left skewed distribution (some cars with low tax)\n",
    "#   - mpg ranges from a negative value (probably wrong data entry) to 470,8 with mean ~55, median 54,3 and std ~16 -> not skewed\n",
    "#   - engineSize ranges from a negative value (probably wrong data entry) to 6,6 with mean ~1,6 median 1.6 and std ~0,5 -> not skewed\n",
    "#   - paintQuality% ranges from 1,6 to 125,6 (should be 0-100% -> probably wrong data entry) with mean ~65, median 28,7 and std ~12 -> not skewed\n",
    "#   - previousOwners ranges from a negative value (probably wrong data entry) to 6,3 (shouldnt be float values -> probably wrong data entry) with mean ~2 median 2 and std ~1,5 -> not skewed but high variance\n",
    "#   - hasDamage is only 0 values -> probably wrong data entries\n",
    "# Categorical:\n",
    "#   - 72 unique brands (though multpiple wrong data entries result in less unique brands (see EDA below))\n",
    "#   - 735 unique models\n",
    "#   - transmission with 40 unique values -> probably wrong data entries because it should be somewhat limited to manual and automatic\n",
    "#   - fuelType with 34 unique values -> probably wrong data entries because it should be limited to petrol, diesel, electric, hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b60f640e-1c37-401c-bce1-290392e2be9a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Inconsistency Check"
    }
   },
   "outputs": [],
   "source": [
    "# print exact unique values of df_cars_train\n",
    "for col in df_cars_train.columns:\n",
    "    print(col, df_cars_train[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Separation of numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize categorical variables (strip whitespace, lowercase)\n",
    "cat_cols = [col for col in df_cars_train.columns if df_cars_train[col].dtype == 'object']\n",
    "print(\"Categorical columns:\", cat_cols)\n",
    "for col in cat_cols:\n",
    "    df_cars_train[col] = df_cars_train[col].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [col for col in df_cars_train.columns if df_cars_train[col].dtype in ['int64', 'float64']]\n",
    "num_cols.remove('carID') # remove carID because its an identifier\n",
    "num_cols.remove('hasDamage') # remove hasDamage because its only 0 or null values\n",
    "\n",
    "print(\"Numerical columns:\", num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neither_categorical_numerical = [col for col in df_cars_train.columns if col not in cat_cols + num_cols]\n",
    "neither_categorical_numerical.remove('carID')\n",
    "neither_categorical_numerical.remove('hasDamage')\n",
    "print(\"Neither categorical nor numerical columns:\", neither_categorical_numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization settings\n",
    "sns.set(style=\"whitegrid\")\n",
    "hist_color = '#1f77b4'   # dark blue\n",
    "box_color = '#ff7f0e'    # warm orange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numerical_univariate_distributions(df, cols):\n",
    "    # figure: 2 features per row (4 plots per row = hist + boxplot per feature)\n",
    "    n_features = len(cols)\n",
    "    n_rows = int(np.ceil(n_features / 2))\n",
    "    fig, axes = plt.subplots(n_rows, 4, figsize=(16, n_rows * 4))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(cols):\n",
    "        # histogram\n",
    "        sns.histplot(df[col], bins=25, color=hist_color, kde=False, ax=axes[i*2])\n",
    "        axes[i*2].set_xlabel('')\n",
    "        axes[i*2].set_ylabel('')\n",
    "        axes[i*2].set_title(f'{col}', fontsize=11, pad=12)\n",
    "\n",
    "        if df[col].dtype in ['int64', 'float64', 'Int64', 'Float64']:\n",
    "            # add mean and median lines\n",
    "            mean_val = df[col].mean()\n",
    "            median_val = df[col].median()\n",
    "            axes[i*2].axvline(mean_val, color='red', linestyle='--', label='Mean')\n",
    "            axes[i*2].axvline(median_val, color='green', linestyle='-', label='Median')\n",
    "            axes[i*2].legend()\n",
    "\n",
    "            # boxplot (vertical)\n",
    "            sns.boxplot(y=df[col], ax=axes[i*2 + 1], color=box_color)\n",
    "            axes[i*2 + 1].set_xlabel('')\n",
    "            axes[i*2 + 1].set_ylabel('')\n",
    "            axes[i*2 + 1].set_title(f'{col}', fontsize=11, pad=12)\n",
    "\n",
    "    # hide any unused axes\n",
    "    for j in range(i*2 + 2, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.suptitle('univariate distributions of numerical features', fontsize=14, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "36e654d9-0893-4966-90eb-7cf33f4c62b6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Univariate Distributions"
    }
   },
   "outputs": [],
   "source": [
    "plot_numerical_univariate_distributions(df_cars_train, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_univariate_distributions(cat_cols)\n",
    "def plot_categorical_distributions(df, cols):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    top_n = 20\n",
    "\n",
    "    for ax, col in zip(axes, cols):\n",
    "        vc = df[col].value_counts().nlargest(top_n)\n",
    "        sns.barplot(x=vc.index, y=vc.values, color=hist_color, ax=ax)\n",
    "        ax.set_title(f'{col}')\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('count')\n",
    "        ax.tick_params(axis='x', rotation=90)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), ha='right')\n",
    "\n",
    "    # hide any unused axes (in case cat_cols length < axes)\n",
    "    for i in range(len(cat_cols), len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 20 most frequent values per categorical column:\")\n",
    "plot_categorical_distributions(df_cars_train, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train['Brand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train['transmission'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train['fuelType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Findings after Descriptive Statistics and Inconsistency Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Warning:</b> Some <b>numerical features</b> (mileage, tax, mpg, engineSize, previousOwner) contain negative entries, which is not possible. Data cleaning is necessary to ensure a more accurate analysis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Warning:</b> All <b>categorical features</b> (brand, model, transmission and fuelType) contain numerous spelling inconsistencies. Data cleaning is necessary to ensure accurate and interpretable results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87c827ae-6704-4616-8782-1d11f7385da3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Numerical:**\n",
    "\n",
    "carID:  \n",
    "- sequential numeric identifier, ranges from **0–75,972**  \n",
    "- no duplicates expected, used only as index/key  \n",
    "\n",
    "year:  \n",
    "- values range from **1970–2024**, mean ≈ **2017**  \n",
    "- years after **2020** are unrealistic (future registration) → invalid entries  \n",
    "- Two cars in year **1970** are outliers with a big gap to the following cars (starting from 1996)\n",
    "- decimals in year (e.g. **2023.367**) → data corruption, round to nearest int  \n",
    "- older outliers before **2000** rare, likely classic or miscoded entries  \n",
    "- can derive **age = 2020 - year** for modeling  \n",
    "\n",
    "mileage:  \n",
    "- range **–58,540 → 323,000**, mean ≈ **23k** → negatives invalid  \n",
    "- missing values around **1.5k**  \n",
    "- strong right skew, some extreme outliers >**250k miles**  \n",
    "- negative or zero values should be filtered or replaced with abs()  \n",
    "\n",
    "tax:  \n",
    "- range **–91 → 580**, mean ≈ **120** → invalid negatives present  \n",
    "- normal values cluster around **125–145**  \n",
    "- decimals and small negatives appear due to calculation/entry errors  \n",
    "- likely strong right skew → a few cars taxed over **500**  \n",
    "- needs capping and replacement for negatives  \n",
    "\n",
    "mpg:  \n",
    "- range **–43 → 470**, mean ≈ **55** → negative and extreme outliers exist  \n",
    "- typical real range **30–70 mpg**, but some values like **470** unrealistic  \n",
    "- invalid entries indicate unit mix-up or input noise  \n",
    "- expected inverse relation with **engine size** and **price**  \n",
    "\n",
    "engineSize:  \n",
    "- range **–0.1 → 6.6L**, mean ≈ **1.66L**, std ≈ **0.57**  \n",
    "- several decimals and negative/zero values → invalid  \n",
    "- expected valid range **0.6–6.0L**  \n",
    "- most cars between **1.2–2.0L** → compact to mid-size engines  \n",
    "- positive correlation with **price** and **tax**  \n",
    "\n",
    "paintQuality%:  \n",
    "- range **1.6 → 125.6%**, mean ≈ **64.6%**  \n",
    "- values above **100%** unrealistic → scaling error  \n",
    "- some extremely low values (**≈1–3%**) indicate outliers or noise  \n",
    "- most cars between **50–80%** → average paint quality  \n",
    "\n",
    "previousOwners:  \n",
    "- range **–2.3 → 6.26**, mean ≈ **2**  \n",
    "- negative values invalid → likely placeholder or encoding issue  \n",
    "- most between **0–3** → typical secondhand ownership distribution  \n",
    "- outliers >**6** likely data entry errors or mis-scaling  \n",
    "- likely negative correlation with **price**  \n",
    "\n",
    "hasDamage:  \n",
    "- only values are **0 and NaN** → no variation  \n",
    "- unclear if NaN means damaged → convert to int and verify meaning  \n",
    "- likely nonfunctional feature → **drop**  \n",
    "\n",
    "price (target):  \n",
    "- range **£450–£159,999**, mean ≈ **£16.9k**, median ≈ **£14.7k** → right-skewed  \n",
    "- typical cars priced **£10k–£21k**, few luxury outliers inflate mean  \n",
    "- consistent integer values, no missing or obvious anomalies  \n",
    "- strong dependence expected on **mileage**, **year**, **engine size**, and **brand**\n",
    "\n",
    "\n",
    "**Categorical:**\n",
    "\n",
    "brand:  \n",
    "- **72 unique brands** with severe spelling and capitalization inconsistencies (**Ford**, **ford**, **FOR**, **ord**, **For**, etc.)  \n",
    "- contains partial or truncated names (**w**, **MW**, **Ope**, **Mercede**) → heavy cleaning required  \n",
    "- **Ford dominates (~15k entries)**, followed by **BMW**, **VW**, **Mercedes**, **Toyota**, **Audi**, **Skoda**, **Hyundai**  \n",
    "- strong class imbalance → use one hot encoding, frequency encoding or median price per brand later  \n",
    "\n",
    "model:  \n",
    "- **735 unique entries** with inconsistent formatting, spacing, capitalization, and partial strings  \n",
    "- duplicates of same model under variations (e.g. *“focus”*, *“ FOCUS”*, *“ Focu”*, *“Focus”*)  \n",
    "- many small typos, truncated or malformed entries (*“Focu”*, *“EcoSpor”*, *“Gol”*, *“Yeti Outdoo”*, etc.)  \n",
    "- heavy normalization needed → strip whitespace, lowercase, and fix common truncations  \n",
    "- dominated by popular models like **Ford Focus**, **VW Golf**, **Vauxhall Astra/Corsa**, **Skoda Octavia**  \n",
    "\n",
    "transmission:  \n",
    "- **40 distinct entries**, mostly spelling variants of *manual*, *automatic*, *semi-auto*  \n",
    "- common corruptions: *manua*, *anual*, *semi-aut*, *utomatic*, *nknow*, etc.  \n",
    "- some leading/trailing spaces (*' manual '*, *' Manual '*)  \n",
    "- categories should be reduced to clean labels: **manual**, **automatic**, **semi-auto**, **unknown**\n",
    "\n",
    "fuelType:\n",
    "- lots of spelling errors\n",
    "- should be limited to petrol, diesel, hybrid and electric\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Univariate after data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train['engineSize'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"NaN entries because of mileage < 0: {len(df_cars_train[df_cars_train['mileage'] < 0])}\")\n",
    "print(f\"NaN entries because of tax < 0: {len(df_cars_train[df_cars_train['tax'] < 0])}. Of those already NaN because of mileage: {len(df_cars_train[(df_cars_train['tax'] < 0) & (df_cars_train['mileage'] < 0)])}\")\n",
    "print(f\"NaN entries because of mpg < 5 and > 150: {len(df_cars_train[df_cars_train['mpg'] < 5])} and {len(df_cars_train[df_cars_train['mpg'] > 150])}. Of those already NaN because of mileage: {len(df_cars_train[(df_cars_train['mpg'] < 5) & (df_cars_train['mileage'] < 0)]) + len(df_cars_train[(df_cars_train['mpg'] > 150) & (df_cars_train['mileage'] < 0)])}. Because of tax: {len(df_cars_train[(df_cars_train['mpg'] < 5) & (df_cars_train['tax'] < 0)]) + len(df_cars_train[(df_cars_train['mpg'] > 150) & (df_cars_train['tax'] < 0)])}\")\n",
    "print(f\"NaN entries because of engineSize < 0 and > 9 : {len(df_cars_train[df_cars_train['engineSize'] < 0])} and {len(df_cars_train[df_cars_train['engineSize'] > 9])}. Of those already NaN because of mileage: {len(df_cars_train[(df_cars_train['engineSize'] < 0) & (df_cars_train['mileage'] < 0)])}. Because of tax: {len(df_cars_train[(df_cars_train['engineSize'] < 0) & (df_cars_train['tax'] < 0)])}. Because of mpg: {len(df_cars_train[(df_cars_train['engineSize'] < 0) & (df_cars_train['mpg'] < 5)]) + len(df_cars_train[(df_cars_train['engineSize'] < 0) & (df_cars_train['mpg'] > 150)])}\")\n",
    "print(f\"Nan entries because of paintQuality < 70 and > 100: {len(df_cars_train.loc[df_cars_train['paintQuality%'].between(70, 100)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of rows without missing values: {df_cars_train.dropna(inplace=False).shape[0]}\")\n",
    "print(f\"Length of dataset before cleaning: {len(df_cars_train)}\")\n",
    "df_cars_train_cleaned = clean_car_dataframe(df_cars_train)\n",
    "print(f\"\\nNumber of rows without missing values after cleaning: {df_cars_train_cleaned.dropna(inplace=False).shape[0]}\")\n",
    "print(f\"Length of dataset after cleaning: {len(df_cars_train_cleaned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols.remove('paintQuality%')\n",
    "num_cols.append('paintQuality')\n",
    "plot_numerical_univariate_distributions(df_cars_train_cleaned, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train_cleaned['paintQuality'].describe() # => after cleaning, min value is 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical_distributions(df_cars_train_cleaned, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train_cleaned['Brand'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train_cleaned['model'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train_cleaned['transmission'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train_cleaned['fuelType'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 New Findings after cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Warning:</b> Setting invalid entries to NaN (e.g. mileage < 0) leads to an entirely different distribution of paintQuality\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical**:\n",
    "\n",
    "mpg:\n",
    "- After the cleaning, the distribution looks very symmetric with a roughly mean=median=54\n",
    "\n",
    "paintQuality:\n",
    "- After the data cleaning (removal of entries with negative values), all paintQuality values are at least 70%, ignoring all entries with values < 70\n",
    "- This could lead to unaccurate price predictions for cars with low paintQuality because this characteristic is not present in the data set\n",
    "\n",
    "Other numerical features:\n",
    "- Except for that, no notable new findings, just cleaner distributions without the invalid negative values (mileage, tax, mpg, engineSize, previousOwner) and unrealistic percentage values (paintQuality).\n",
    "\n",
    "\n",
    "**Categorical:**\n",
    "\n",
    "brand:\n",
    "- **Only 9 unique brands** left after cleaning the strings\n",
    "- from 3400 (Hyundai) to ~16.000 (Ford) entries\n",
    "- **108 NaNs** that will be imputed in preprocessing\n",
    "\n",
    "model:\n",
    "- **Only 114 unique models** left after cleaning the strings\n",
    "- **4 cars** with **over 3500 entries** dominate the dataset (focus, c class, fiesta, golf)\n",
    "- **5121 NaNs** that will be imputed in preprocessing\n",
    "\n",
    "transmission:\n",
    "- **Most** of the cars are **Manual** (41615/75973)\n",
    "- **Semi-Auto and Automatic** are roughly **equally distributed** (16867 and 15205)\n",
    "- Some entries are Unknown (735) or marked as Other (5) -> has to be dealt with in preprocessing\n",
    "- **1546 NaNs** that will be imputed in preprocessing\n",
    "\n",
    "fuelType:\n",
    "- Nearly all cars are **Petrol or Diesel** (41181 and 30885)\n",
    "- Some Hybrids (2225) and **barely no Electrics (4)** -> has to be paid attention when feature of car in test set is electric\n",
    "- Some marked as Other (167) -> has to be dealt with in preprocessing\n",
    "- **1511 NaNs** that will be imputed in preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why we decided to use Spearman correlation:**\n",
    "\n",
    "- the numeric variables (price, mileage, mpg, tax, engineSize) are **non-normally distributed and contain outliers**, causing linear measures like pearson to distort correlation strength.  \n",
    "- **spearman** evaluates *monotonic* relationships based on rank order rather than exact linearity, making it **robust to skewness and outliers**.  \n",
    "- this allows us to correctly capture the direction and magnitude of real-world trends, such as price decreasing with mileage, even if not perfectly linear.  \n",
    "- after cleaning and scaling the data, we will revisit **pearson correlation** for linear modeling checks, but **spearman is more appropriate for initial EDA**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0d9d97a2-8ecc-41e2-81e0-abe470940a9b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Correlations"
    }
   },
   "outputs": [],
   "source": [
    "# pearson and spearman correlation\n",
    "corr_pearson = df_cars_train_cleaned[num_cols].corr(method='pearson', numeric_only=True).round(2)\n",
    "corr_spearman = df_cars_train_cleaned[num_cols].corr(method='spearman', numeric_only=True).round(2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "mask = np.triu(np.ones_like(corr_spearman, dtype=bool))\n",
    "\n",
    "sns.heatmap(corr_pearson, mask=mask, annot=True, cmap='coolwarm', center=0, fmt='.2f',\n",
    "            linewidths=0.5, ax=axes[0], cbar=False)\n",
    "axes[0].set_title('pearson correlation (linear)')\n",
    "\n",
    "sns.heatmap(corr_spearman, mask=mask, annot=True, cmap='coolwarm', center=0, fmt='.2f',\n",
    "            linewidths=0.5, ax=axes[1], cbar_kws={'label': 'correlation strength'})\n",
    "axes[1].set_title('spearman correlation (monotonic)')\n",
    "\n",
    "plt.suptitle('comparison of pearson vs spearman correlation', fontsize=14, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8efa37e9-9ab5-472e-8514-8e7b6b832be4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Findings after correlation:**\n",
    "\n",
    "- price shows **strong positive correlation with year (0.60)** → newer cars are priced higher  \n",
    "- price is **positively correlated with engineSize (0.56)** → larger engines increase car value  \n",
    "- price is **moderately negatively correlated with mileage (–0.51)** → more driven cars lose value  \n",
    "- mpg correlates **negatively with price (–0.39)** → efficient cars are typically smaller and cheaper  \n",
    "- tax has a **moderate positive correlation (0.31)** with price → more expensive cars often have higher taxes  \n",
    "- year and mileage have a **very strong negative correlation (–0.78)** → newer cars have lower mileage  \n",
    "- mpg and tax are **strongly negatively correlated (–0.55)** → efficient cars usually taxed less  \n",
    "- engineSize and mpg **correlate negatively (–0.20) → larger engines are less fuel-efficient  \n",
    "- paintQuality% and previousOwners show **near-zero correlations** with all other variables → low predictive relevance  \n",
    "- overall, **price mainly depends on year, engineSize, mileage, and mpg**, which align with intuitive market behavior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. EDA on engineered features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering from main notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "exploratory_data_analysis",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
