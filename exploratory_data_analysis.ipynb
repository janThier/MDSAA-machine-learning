{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52359b17-1216-4744-a528-81e23a033a68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Project Cars4you (Group 5): Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cars 4 You is an online car resale company that sells cars from multiple different brands.  \n",
    "Their main goal is to expedite the evaluation process by creating a predictive model capable of evaluating the price of a car based on the user’s input without needing the car to be taken to a mechanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Attribute**       | **Description** |\n",
    "|----------------------|-----------------|\n",
    "| **carID**            | An attribute that contains an identifier for each car. |\n",
    "| **Brand**            | The car’s main brand (e.g. Ford, Toyota) |\n",
    "| **model**            | The car model |\n",
    "| **year**             | The year of Registration of the Car |\n",
    "| **mileage**          | The total reported distance travelled by the car (in miles) |\n",
    "| **tax**              | The amount of road tax (in £) that, in 2020, was applicable to the car in question. |\n",
    "| **fuelType**         | Type of Fuel used by the car (Diesel, Petrol, Hybrid, Electric) |\n",
    "| **mpg**              | Average Miles per Gallon (fuel efficiency) |\n",
    "| **engineSize**       | Size of engine in liters (cubic decimeters) |\n",
    "| **paintQuality%**    | The mechanic’s assessment of the cars’ overall paint quality and hull integrity (filled by the mechanic during evaluation). |\n",
    "| **previousOwners**   | Number of previous registered owners of the vehicle |\n",
    "| **hasDamage**        | Boolean marker filled by the seller at the time of registration stating whether the car is damaged or not |\n",
    "| **price (TARGET)**            | The car’s price when purchased by Cars 4 You (in £) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b65f0ae-0d7a-4cdb-830a-391a209b82d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "TASK I (3 Points): Descriptive Statistics, Inconsistency Check, Visual Data Explorance, Extraction of Relevant Insights, Multivariate Relationships  => Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27fff3e4-624f-4b1f-b258-fbbe7b69cb00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1. Import & load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f54ab11e-fcfc-4278-8997-89a92adf8eff",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import and load Data"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "from data_cleaning import clean_car_dataframe\n",
    "from itertools import combinations\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train = pd.read_csv(\"train.csv\")\n",
    "df_cars_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basic Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "00193525-37c5-4d69-bc00-605d8fb49f7d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Decriptive Statistics"
    }
   },
   "outputs": [],
   "source": [
    "# Overview of structure and data types\n",
    "df_cars_train.info()\n",
    "\n",
    "# Strip whitespace and lowercase before duplicate check\n",
    "df_cars_train = df_cars_train.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate rows: {df_cars_train.duplicated().sum()}\") # 0\n",
    "\n",
    "# Check for duplicate carID\n",
    "print(f\"\\nDuplicate carID: {df_cars_train['carID'].duplicated().sum()}\") # 0\n",
    "print(f\"Null values in column carID: {df_cars_train['carID'].isnull().sum()}\") # 0\n",
    "print(f\"All carID entries are unique: {df_cars_train['carID'].nunique()}/{len(df_cars_train)}\")\n",
    "\n",
    "\n",
    "# Findings:\n",
    "#   - missing values in every column except carID and price\n",
    "#   - year, mpg, previousOwners, hasDamage as float seems weird\n",
    "#   - no duplicates in all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_cars_train.describe().T)\n",
    "display(df_cars_train.describe(include=\"object\").T)\n",
    "\n",
    "### First Findings (extensive description of each attribute in Univariate Section):\n",
    "# Numerical:\n",
    "#   - carID is unique identifier\n",
    "#   - years range from 1970 to 2024.12 (a float so maybe some have month info?) with most of the cars being between 2016 and 2019 (max value of 2024 doesnt make sense because database is from 2020)\n",
    "#   - price ranges from 450 to 159.999 with mean ~17.000, median ~14.500 and std ~10.000 -> right skewed distribution (some cars with high prices)\n",
    "#   - mileage ranges from a negative value (probably wrong data entry) to 323.000 with mean ~23.000, median 17300 and std ~22.000 -> right skewed distribution (some cars with very high mileage) and high variance\n",
    "#   - tax ranges from a negative value (probably wrong data entry) to 580 with mean ~120, median 145 and std ~65 -> left skewed distribution (some cars with low tax)\n",
    "#   - mpg ranges from a negative value (probably wrong data entry) to 470,8 with mean ~55, median 54,3 and std ~16 -> not skewed\n",
    "#   - engineSize ranges from a negative value (probably wrong data entry) to 6,6 with mean ~1,6 median 1.6 and std ~0,5 -> not skewed\n",
    "#   - paintQuality% ranges from 1,6 to 125,6 (should be 0-100% -> probably wrong data entry) with mean ~65, median 28,7 and std ~12 -> not skewed\n",
    "#   - previousOwners ranges from a negative value (probably wrong data entry) to 6,3 (shouldnt be float values -> probably wrong data entry) with mean ~2 median 2 and std ~1,5 -> not skewed but high variance\n",
    "#   - hasDamage is only 0 values -> probably wrong data entries\n",
    "# Categorical:\n",
    "#   - 72 unique brands (though multpiple wrong data entries result in less unique brands (see EDA below))\n",
    "#   - 735 unique models\n",
    "#   - transmission with 40 unique values -> probably wrong data entries because it should be somewhat limited to manual and automatic\n",
    "#   - fuelType with 34 unique values -> probably wrong data entries because it should be limited to petrol, diesel, electric, hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b60f640e-1c37-401c-bce1-290392e2be9a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Inconsistency Check"
    }
   },
   "outputs": [],
   "source": [
    "# print exact unique values of df_cars_train\n",
    "for col in df_cars_train.columns:\n",
    "    print(col, df_cars_train[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Separation of numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize categorical variables (strip whitespace, lowercase)\n",
    "cat_cols = [col for col in df_cars_train.columns if df_cars_train[col].dtype == 'object']\n",
    "print(\"Categorical columns:\", cat_cols)\n",
    "for col in cat_cols:\n",
    "    df_cars_train[col] = df_cars_train[col].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [col for col in df_cars_train.columns if df_cars_train[col].dtype in ['int64', 'float64']]\n",
    "num_cols.remove('carID') # remove carID because its an identifier\n",
    "num_cols.remove('hasDamage') # remove hasDamage because its only 0 or nan values and even when imputing nan to 1 it has no correlatin with price\n",
    "df_cars_train['hasDamage'].value_counts(dropna=False)\n",
    "damaged_to_1 = df_cars_train['hasDamage'].fillna(1).astype('Int64')\n",
    "damaged_to_1.value_counts(dropna=False)\n",
    "hasDamage_price_corr = damaged_to_1.corr(df_cars_train['price']).round(4)\n",
    "\n",
    "print(f\"hasDamage with filled NaN to 1 correlation with price ({hasDamage_price_corr}) is ~0 so its not worth it to make the assumption that NaN means damaged => The feature will be ignored.\")\n",
    "\n",
    "print(\"Numerical columns:\", num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neither_categorical_numerical = [col for col in df_cars_train.columns if col not in cat_cols + num_cols]\n",
    "neither_categorical_numerical.remove('carID')\n",
    "neither_categorical_numerical.remove('hasDamage')\n",
    "print(\"Neither categorical nor numerical columns:\", neither_categorical_numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization settings\n",
    "sns.set(style=\"whitegrid\")\n",
    "hist_color = '#1f77b4'   # dark blue\n",
    "box_color = '#ff7f0e'    # warm orange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numerical_univariate_distributions(df, cols):\n",
    "    # figure: 2 features per row (4 plots per row = hist + boxplot per feature)\n",
    "    n_features = len(cols)\n",
    "    n_rows = int(np.ceil(n_features / 2))\n",
    "    fig, axes = plt.subplots(n_rows, 4, figsize=(16, n_rows * 4))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(cols):\n",
    "        # histogram\n",
    "        sns.histplot(df[col], bins=25, color=hist_color, kde=False, ax=axes[i*2])\n",
    "        axes[i*2].set_xlabel('')\n",
    "        axes[i*2].set_ylabel('')\n",
    "        axes[i*2].set_title(f'{col}', fontsize=11, pad=12)\n",
    "\n",
    "        if df[col].dtype in ['int64', 'float64', 'Int64', 'Float64']:\n",
    "            # add mean and median lines\n",
    "            mean_val = df[col].mean()\n",
    "            median_val = df[col].median()\n",
    "            axes[i*2].axvline(mean_val, color='red', linestyle='--', label='Mean')\n",
    "            axes[i*2].axvline(median_val, color='green', linestyle='-', label='Median')\n",
    "            axes[i*2].legend()\n",
    "\n",
    "            # boxplot (vertical)\n",
    "            sns.boxplot(y=df[col], ax=axes[i*2 + 1], color=box_color)\n",
    "            axes[i*2 + 1].set_xlabel('')\n",
    "            axes[i*2 + 1].set_ylabel('')\n",
    "            axes[i*2 + 1].set_title(f'{col}', fontsize=11, pad=12)\n",
    "\n",
    "    # hide any unused axes\n",
    "    for j in range(i*2 + 2, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.suptitle('univariate distributions of numerical features', fontsize=14, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "36e654d9-0893-4966-90eb-7cf33f4c62b6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Univariate Distributions"
    }
   },
   "outputs": [],
   "source": [
    "plot_numerical_univariate_distributions(df_cars_train, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the gap in paintQuality\n",
    "print(df_cars_train['paintQuality%'].unique())\n",
    "display(df_cars_train[df_cars_train['paintQuality%'] < 4].sort_values('paintQuality%'))\n",
    "display(df_cars_train[df_cars_train['paintQuality%'] >= 4].sort_values('paintQuality%'))\n",
    "df_cars_train[df_cars_train['paintQuality%'].between(4, 29)]\n",
    "print(\"==> Remove paintQuality values below 5 and above 100 as outliers in data cleaning step. These values are not just outliers but also stored as float values which is inconsistent with the other values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_univariate_distributions(cat_cols)\n",
    "def plot_categorical_distributions(df, cols):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    top_n = 20\n",
    "\n",
    "    for ax, col in zip(axes, cols):\n",
    "        vc = df[col].value_counts().nlargest(top_n)\n",
    "        sns.barplot(x=vc.index, y=vc.values, color=hist_color, ax=ax)\n",
    "        ax.set_title(f'{col}')\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('count')\n",
    "        ax.tick_params(axis='x', rotation=90)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), ha='right')\n",
    "\n",
    "    # hide any unused axes (in case cat_cols length < axes)\n",
    "    for i in range(len(cat_cols), len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 20 most frequent values per categorical column:\")\n",
    "plot_categorical_distributions(df_cars_train, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train['Brand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train['transmission'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train['fuelType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Findings after Descriptive Statistics and Inconsistency Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Attention:</b> The target variable (price) is right-skewed -> requires log-transform for linear models.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Warning:</b> Some <b>numerical features</b> (mileage, tax, mpg, engineSize, previousOwner) contain negative entries, which is not possible. Data cleaning is necessary to ensure a more accurate analysis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Warning:</b> All <b>categorical features</b> (brand, model, transmission and fuelType) contain numerous spelling inconsistencies. Data cleaning is necessary to ensure accurate and interpretable results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87c827ae-6704-4616-8782-1d11f7385da3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Numerical:**\n",
    "\n",
    "price (Target variable):  \n",
    "- range **£450–£159,999**, mean ≈ **£16.9k**, median ≈ **£14.7k** → right-skewed (log-transform useful before building a linear regression model)  \n",
    "- typical cars priced **£10k–£21k**, few luxury outliers inflate mean  \n",
    "- consistent integer values, no missing or obvious anomalies  \n",
    "- strong dependence expected on **mileage**, **year**, **engine size**, and **brand**\n",
    "\n",
    "carID:  \n",
    "- sequential numeric identifier, ranges from **0–75,972**  \n",
    "- no duplicates expected, used only as index/key  \n",
    "\n",
    "year:  \n",
    "- values range from **1970–2024**, mean ≈ **2017**  \n",
    "- years after **2020** are unrealistic (future registration) → invalid entries  \n",
    "- Two cars in year **1970** are outliers with a big gap to the following cars (starting from 1996)\n",
    "- decimals in year (e.g. **2023.367**) → data corruption, round to nearest int  \n",
    "- older outliers before **2000** rare, likely classic or miscoded entries  \n",
    "- can derive **age = 2020 - year** for modeling  \n",
    "\n",
    "mileage:  \n",
    "- range **–58,540 → 323,000**, mean ≈ **23k** → negatives invalid  \n",
    "- missing values around **1.5k**  \n",
    "- strong right skew, some extreme outliers >**250k miles**  \n",
    "- negative or zero values should be filtered or replaced with abs()  \n",
    "\n",
    "tax:  \n",
    "- range **–91 → 580**, mean ≈ **120** → invalid negatives present  \n",
    "- normal values cluster around **125–145**  \n",
    "- decimals and small negatives appear due to calculation/entry errors  \n",
    "- likely strong right skew → a few cars taxed over **500**  \n",
    "- needs capping and replacement for negatives  \n",
    "\n",
    "mpg:  \n",
    "- range **–43 → 470**, mean ≈ **55** → negative and extreme outliers exist  \n",
    "- typical real range **30–70 mpg**, but some values like **470** unrealistic  \n",
    "- invalid entries indicate unit mix-up or input noise  \n",
    "- expected inverse relation with **engine size** and **price**  \n",
    "\n",
    "engineSize:  \n",
    "- range **–0.1 → 6.6L**, mean ≈ **1.66L**, std ≈ **0.57**  \n",
    "- several decimals and negative/zero values → invalid  \n",
    "- expected valid range **0.6–6.0L**  \n",
    "- most cars between **1.2–2.0L** → compact to mid-size engines  \n",
    "- positive correlation with **price** and **tax**  \n",
    "\n",
    "paintQuality%:  \n",
    "- range **1.6 → 125.6%**, mean ≈ **64.6%**  \n",
    "- values above **100%** unrealistic → scaling error  \n",
    "- some extremely low values (**≈1–3%**) indicate outliers or noise  \n",
    "- most cars between **50–80%** → average paint quality  \n",
    "- **No values between 4 and 29** → Remove values < 5 and > 100 because they are not only outliers but also stored as float values which is inconsistent with the other values suggesting wrong data entry.\n",
    "\n",
    "previousOwners:  \n",
    "- range **–2.3 → 6.26**, mean ≈ **2**  \n",
    "- negative values invalid → likely placeholder or encoding issue  \n",
    "- most between **0–3** → typical secondhand ownership distribution  \n",
    "- outliers >**6** likely data entry errors or mis-scaling  \n",
    "- likely negative correlation with **price**  \n",
    "\n",
    "hasDamage:  \n",
    "- only values are **0 and NaN** → no variation  \n",
    "- unclear if NaN means damaged → convert to int and verify meaning  \n",
    "- likely nonfunctional feature → **drop**  \n",
    "\n",
    "\n",
    "**Categorical:**\n",
    "\n",
    "brand:  \n",
    "- **72 unique brands** with severe spelling and capitalization inconsistencies (**Ford**, **ford**, **FOR**, **ord**, **For**, etc.)  \n",
    "- contains partial or truncated names (**w**, **MW**, **Ope**, **Mercede**) → heavy cleaning required  \n",
    "- **Ford dominates (~15k entries)**, followed by **BMW**, **VW**, **Mercedes**, **Toyota**, **Audi**, **Skoda**, **Hyundai**  \n",
    "- strong class imbalance → use one hot encoding, frequency encoding or median price per brand later  \n",
    "\n",
    "model:  \n",
    "- **735 unique entries** with inconsistent formatting, spacing, capitalization, and partial strings  \n",
    "- duplicates of same model under variations (e.g. *“focus”*, *“ FOCUS”*, *“ Focu”*, *“Focus”*)  \n",
    "- many small typos, truncated or malformed entries (*“Focu”*, *“EcoSpor”*, *“Gol”*, *“Yeti Outdoo”*, etc.)  \n",
    "- heavy normalization needed → strip whitespace, lowercase, and fix common truncations  \n",
    "- dominated by popular models like **Ford Focus**, **VW Golf**, **Vauxhall Astra/Corsa**, **Skoda Octavia**  \n",
    "\n",
    "transmission:  \n",
    "- **40 distinct entries**, mostly spelling variants of *manual*, *automatic*, *semi-auto*  \n",
    "- common corruptions: *manua*, *anual*, *semi-aut*, *utomatic*, *nknow*, etc.  \n",
    "- some leading/trailing spaces (*' manual '*, *' Manual '*)  \n",
    "- categories should be reduced to clean labels: **manual**, **automatic**, **semi-auto**, **unknown**\n",
    "\n",
    "fuelType:\n",
    "- lots of spelling errors\n",
    "- should be limited to petrol, diesel, hybrid and electric\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Univariate after data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"NaN entries because of mileage < 0: {len(df_cars_train[df_cars_train['mileage'] < 0])}\")\n",
    "print(f\"NaN entries because of tax < 0: {len(df_cars_train[df_cars_train['tax'] < 0])}. Of those already NaN because of mileage: {len(df_cars_train[(df_cars_train['tax'] < 0) & (df_cars_train['mileage'] < 0)])}\")\n",
    "print(f\"NaN entries because of mpg < 5 and > 150: {len(df_cars_train[df_cars_train['mpg'] < 5])} and {len(df_cars_train[df_cars_train['mpg'] > 150])}. Of those already NaN because of mileage: {len(df_cars_train[(df_cars_train['mpg'] < 5) & (df_cars_train['mileage'] < 0)]) + len(df_cars_train[(df_cars_train['mpg'] > 150) & (df_cars_train['mileage'] < 0)])}. Because of tax: {len(df_cars_train[(df_cars_train['mpg'] < 5) & (df_cars_train['tax'] < 0)]) + len(df_cars_train[(df_cars_train['mpg'] > 150) & (df_cars_train['tax'] < 0)])}\")\n",
    "print(f\"NaN entries because of engineSize < 0 and > 9 : {len(df_cars_train[df_cars_train['engineSize'] < 0])} and {len(df_cars_train[df_cars_train['engineSize'] > 9])}. Of those already NaN because of mileage: {len(df_cars_train[(df_cars_train['engineSize'] < 0) & (df_cars_train['mileage'] < 0)])}. Because of tax: {len(df_cars_train[(df_cars_train['engineSize'] < 0) & (df_cars_train['tax'] < 0)])}. Because of mpg: {len(df_cars_train[(df_cars_train['engineSize'] < 0) & (df_cars_train['mpg'] < 5)]) + len(df_cars_train[(df_cars_train['engineSize'] < 0) & (df_cars_train['mpg'] > 150)])}\")\n",
    "print(f\"Nan entries because of paintQuality < 0 and > 100: {len(df_cars_train[(df_cars_train['paintQuality%'] < 0) | (df_cars_train['paintQuality%'] > 100)])}. Of those already NaN because of mileage: {len(df_cars_train[((df_cars_train['paintQuality%'] < 0) | (df_cars_train['paintQuality%'] > 100)) & (df_cars_train['mileage'] < 0)])}. Because of tax: {len(df_cars_train[((df_cars_train['paintQuality%'] < 0) | (df_cars_train['paintQuality%'] > 100)) & (df_cars_train['tax'] < 0)])}. Because of mpg: {len(df_cars_train[((df_cars_train['paintQuality%'] < 0) | (df_cars_train['paintQuality%'] > 100)) & (df_cars_train['mpg'] < 5 | (df_cars_train['mpg'] > 150))])}. Because of engineSize: {len(df_cars_train[((df_cars_train['paintQuality%'] < 0) | (df_cars_train['paintQuality%'] > 100)) & (df_cars_train['engineSize'] < 0 | (df_cars_train['engineSize'] > 9))])}\")\n",
    "print(f\"Nan entries because of previousOwners < 0 : {len(df_cars_train[df_cars_train['previousOwners'] < 0])}. Of those already NaN because of mileage: {len(df_cars_train[(df_cars_train['previousOwners'] < 0) & (df_cars_train['mileage'] < 0)])}. Because of tax: {len(df_cars_train[(df_cars_train['previousOwners'] < 0) & (df_cars_train['tax'] < 0)])}. Because of mpg: {len(df_cars_train[(df_cars_train['previousOwners'] < 0) & (df_cars_train['mpg'] < 5)]) + len(df_cars_train[(df_cars_train['previousOwners'] < 0) & (df_cars_train['mpg'] > 150)])}. Because of engineSize: {len(df_cars_train[(df_cars_train['previousOwners'] < 0) & (df_cars_train['engineSize'] < 0)]) + len(df_cars_train[(df_cars_train['previousOwners'] < 0) & (df_cars_train['engineSize'] > 9)])}. Because of paintQuality: {len(df_cars_train[(df_cars_train['previousOwners'] < 0) & ((df_cars_train['paintQuality%'] < 0) | (df_cars_train['paintQuality%'] > 100))])}\")\n",
    "\n",
    "print(\"\\n ==> Barely any overlaps between NaN entries of different columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of rows without missing values: {df_cars_train.dropna(inplace=False).shape[0]}\")\n",
    "print(f\"Length of dataset before cleaning: {len(df_cars_train)}\")\n",
    "df_cars_train_cleaned = clean_car_dataframe(df_cars_train)\n",
    "print(f\"\\nNumber of rows without missing values after cleaning: {df_cars_train_cleaned.dropna(inplace=False).shape[0]}\")\n",
    "print(f\"Length of dataset after cleaning: {len(df_cars_train_cleaned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols.remove('paintQuality%')\n",
    "num_cols.append('paintQuality')\n",
    "plot_numerical_univariate_distributions(df_cars_train_cleaned, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical_distributions(df_cars_train_cleaned, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train_cleaned['Brand'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train_cleaned['model'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train_cleaned['transmission'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train_cleaned['fuelType'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 New Findings after cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical**:\n",
    "\n",
    "paintQuality:\n",
    "- ranges from 30-100 now without the (probably invalid) outliers\n",
    "- roughly equally distributed\n",
    "\n",
    "mpg:\n",
    "- After the cleaning, the distribution looks very **symmetric** with a roughly mean=median=54\n",
    "\n",
    "Other numerical features:\n",
    "- Except for that, no notable new findings, just cleaner distributions without the invalid negative values (mileage, tax, mpg, engineSize, previousOwner) and unrealistic percentage values (paintQuality).\n",
    "\n",
    "\n",
    "**Categorical:**\n",
    "\n",
    "brand:\n",
    "- **Only 9 unique brands** left after cleaning the strings\n",
    "- from 3400 (Hyundai) to ~16.000 (Ford) entries\n",
    "- **108 NaNs** that will be imputed in preprocessing\n",
    "\n",
    "model:\n",
    "- **Only 114 unique models** left after cleaning the strings\n",
    "- **4 cars** with **over 3500 entries** dominate the dataset (focus, c class, fiesta, golf)\n",
    "- **5121 NaNs** that will be imputed in preprocessing\n",
    "\n",
    "transmission:\n",
    "- **Most** of the cars are **Manual** (41615/75973)\n",
    "- **Semi-Auto and Automatic** are roughly **equally distributed** (16867 and 15205)\n",
    "- Some entries are Unknown (735) or marked as Other (5) -> has to be dealt with in preprocessing\n",
    "- **1546 NaNs** that will be imputed in preprocessing\n",
    "\n",
    "fuelType:\n",
    "- Nearly all cars are **Petrol or Diesel** (41181 and 30885)\n",
    "- Some Hybrids (2225) and **barely no Electrics (4)** -> has to be paid attention when feature of car in test set is electric\n",
    "- Some marked as Other (167) -> has to be dealt with in preprocessing\n",
    "- **1511 NaNs** that will be imputed in preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bivariate analysis is performed on the cleaned data to ensure a reliable analysis that is not hindered by invalid values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Numerical-Numerical Associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Pairplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairplots to visualize the relationships before computing metrics like correlation to quantify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(df_cars_train_cleaned[num_cols], diag_kind='kde', corner=True) # NAs are included because they will be imputed and therefore should be part of the distribution\n",
    "g.figure.suptitle('Numeric Features — Pairwise Relationships', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Attention:</b> Heteroscedastic relationships between target (price) and predictors (years, mileage) violate the assumption of linear models → Linear regression models are probably not be the best choice for this dataset (log-transform necessary).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings** (more details in the Findings Correlation section)\n",
    "\n",
    "Price (Target variable):\n",
    "- **Very strong positive and heteroscedastic relationship with years**: The most expensive cars are the newest cars with the spread for new cars being higher than for old cars → Cheap new cars exist while there is no expensive very old car in the data\n",
    "- **Strong Negative and heteroscedastic relationship with mileage**: As mileage increases, the price decreases. At low mileage, there is a huge range of possible prices. At high mileage, all cars have a low price, and the spread is very small. → Some older cars have been driven long distances, while others have relatively low mileage despite their age\n",
    "- **Negative and heteroscedastic relationship with mpg**: However, low-mpg cars have a very wide range of prices while high-mpg cars are almost all in the low-price bracket.\n",
    "- **Strong positive and heteroscedastic relationship with engineSize**: As engineSize increases, price tends to increase. No very expensive cars with very small engine size.\n",
    "- **Relationship seems to be negative with previousOwners**: Cars with many previous owners are found only in the lowest price bracket.\n",
    "- **No clear relationship with paintQuality**: Values appear to be spread randomly across all price points → Variable will likely be a poor predictor of price\n",
    "\n",
    "Relationships between independent variables will be analyzed explicitly in the Correlation Section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why we decided to use Spearman correlation:**\n",
    "\n",
    "- the numeric variables (price, mileage, tax, engineSize) are **non-normally distributed and contain outliers**, causing linear measures like pearson to distort correlation strength.  \n",
    "- **spearman** evaluates **monotonic** relationships based on rank order rather than exact linearity, making it **robust to skewness and outliers**.  \n",
    "- this allows us to correctly capture the direction and magnitude of real-world trends, such as price decreasing with mileage, even if not perfectly linear.  \n",
    "- **pearson correlation** is plotted for linear modeling checks, but **spearman is more appropriate for initial EDA**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0d9d97a2-8ecc-41e2-81e0-abe470940a9b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Correlations"
    }
   },
   "outputs": [],
   "source": [
    "# pearson and spearman correlation\n",
    "corr_pearson = df_cars_train_cleaned[num_cols].corr(method='pearson', numeric_only=True).round(2)\n",
    "corr_spearman = df_cars_train_cleaned[num_cols].corr(method='spearman', numeric_only=True).round(2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "mask = np.triu(np.ones_like(corr_spearman, dtype=bool))\n",
    "\n",
    "sns.heatmap(corr_pearson, mask=mask, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0, fmt='.2f',\n",
    "            linewidths=0.5, ax=axes[0], cbar=False)\n",
    "axes[0].set_title('pearson correlation (linear)')\n",
    "\n",
    "sns.heatmap(corr_spearman, mask=mask, annot=True, cmap='coolwarm',vmin=-1, vmax=1, center=0, fmt='.2f',\n",
    "            linewidths=0.5, ax=axes[1], cbar_kws={'label': 'correlation strength'})\n",
    "axes[1].set_title('spearman correlation (monotonic)')\n",
    "\n",
    "plt.suptitle('comparison of pearson vs spearman correlation', fontsize=14, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8efa37e9-9ab5-472e-8514-8e7b6b832be4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Findings based on spearman correlation:**\n",
    "\n",
    "Price (target variable):\n",
    "- price shows **strong positive correlation with year (0.60)** → newer cars are priced higher  \n",
    "- price is **positively correlated with engineSize (0.57)** → larger engines increase car value  \n",
    "- price is **moderately negatively correlated with mileage (–0.52)** → more driven cars lose value  \n",
    "- price correlates **negatively with mpg (–0.39)** → efficient cars are typically smaller and cheaper  \n",
    "- tax has a **moderate positive correlation (0.32)** with price → more expensive cars often have higher taxes  \n",
    "\n",
    "Correlations between independent variables (potential multicollinearity, strong correlation indicates overlapping information about the dependent variable):\n",
    "- year and mileage have a **very strong negative correlation (–0.79)** → newer cars have lower mileage \n",
    "- year has a **moderate positive correlation with tax (0.32)** -> newer cars have higher tax\n",
    "- year has a **moderate negative correlation with mpg (–0.32)** -> newer cars are more efficient\n",
    "- mileage is **moderately negatively correlated with tax (-0.26)** -> more driven cars have lower tax\n",
    "- mileage is **moderately correlated with mpg (0.33)** -> more driven cars are less efficient\n",
    "- tax and mpg are **strongly negatively correlated (–0.56)** → efficient cars usually taxed less\n",
    "- mpg and engineSize **correlate negatively (–0.21)** → larger engines are less fuel-efficient  \n",
    "- **paintQuality and previousOwners** show **near-zero correlations** with all other variables → low predictive relevance  \n",
    "\n",
    "=> Overall, **price mainly depends on year, engineSize, mileage, and mpg**, which align with intuitive market behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Numerical-Categorical Associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use boxplots to see whether numerical features vary depending on the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_palette(\"vlag\")\n",
    "\n",
    "# One figure (grid) per numerical variable in relation to all categorical variables\n",
    "def plot_categorical_boxplots(num, cat_cols):\n",
    "    n = len(cat_cols)\n",
    "    rows = math.ceil(n / 3)\n",
    "    cols = min(3, n)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(16, 5 * rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax, cat in zip(axes, cat_cols):\n",
    "        sns.boxplot(\n",
    "            data=df_cars_train_cleaned,\n",
    "            x=cat,\n",
    "            y=num,\n",
    "            ax=ax\n",
    "        )\n",
    "        ax.set_title(f\"{num} by {cat}\")\n",
    "        ax.tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "    # hide any unused axes\n",
    "    for ax in axes[n:]:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    fig.suptitle(f\"Distribution of {num} across categorical features\", fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "cat_cols_for_bivariate = cat_cols.copy()\n",
    "cat_cols_for_bivariate.remove('model')  # too many unique values\n",
    "for num in num_cols:\n",
    "    plot_categorical_boxplots(num, cat_cols_for_bivariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**\n",
    "\n",
    "Price (Target variable):\n",
    "- Audi, BMW and Mercedes are the most expensive brands\n",
    "- There are no Manual cars with very high prices\n",
    "- The most expensive cars are petrol cars\n",
    "\n",
    "Years:\n",
    "- \"Other\" transmissions has no old data entry -> could indicate new process for registering transmission\n",
    "- \"Eletric\" fuelType has no old data entries -> could indicate new developments in the market\n",
    "\n",
    "Mileage:\n",
    "- Highest mileage cars are Diesel cars -> Diesel cars seem to have the longest lifetime\n",
    "\n",
    "Tax:\n",
    "- For Hybrid and Electric vehicles are no high taxes recorded -> Either because of lack of enough samples or because they are taxed less than other fuel types\n",
    "\n",
    "Mpg:\n",
    "- BMW has multiple outliers with a high mpg -> potentially big cars with low fuel efficiency\n",
    "- Hybrid cars have higher mpg than petrol or diesel cars -> probably because of electric motor assistance\n",
    "\n",
    "engineSize:\n",
    "- varies a lot for BMW and Mercedes -> potentially some cars with high-performance engines and some with standard engines\n",
    "- the biggest engines are petrol cars\n",
    "\n",
    "Distribution of previous owners and paintQuality across categorical features don't provide any insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Categorical-Categorical Associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of categorical associations is not immediately important because we don't see the relationship with the numeric target variable (price). However, it is important to understand how the other features relate to each other.\n",
    "\n",
    "Stacked bar chart to show how one categorical variable is distributed within another → useful to spot **group differences**, **patterns**, and **imbalances** in the data.  \n",
    "Cramér’s V complements the visuals with a metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Stacked bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars_train_cleaned_stacked_bars = df_cars_train_cleaned.copy()\n",
    "print(\"Categorical columns for bivariate analysis:\", cat_cols_for_bivariate)\n",
    "# Helper to compute %\n",
    "def stacked_percent(df, g1, g2):\n",
    "    tmp = df[[g1, g2]].dropna()\n",
    "    share = (\n",
    "        tmp.groupby([g1, g2]).size()\n",
    "        .groupby(level=0).apply(lambda x: x / x.sum() * 100)\n",
    "        .unstack(fill_value=0)\n",
    "    )\n",
    "    return share\n",
    "\n",
    "pairings = list(combinations(cat_cols_for_bivariate , 2))\n",
    "\n",
    "# Plot grid\n",
    "n = len(pairings)\n",
    "cols = 3\n",
    "rows = -(-n // cols)  # ceiling division\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, rows*4))\n",
    "axes = axes.ravel()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"vlag\")\n",
    "\n",
    "for ax, (cat1, cat2) in zip(axes, pairings):\n",
    "    dist = stacked_percent(df_cars_train_cleaned_stacked_bars, cat1, cat2)\n",
    "    dist.plot(kind=\"bar\", stacked=True, ax=ax, alpha=0.85)\n",
    "\n",
    "    ax.set_title(f\"{cat2} by {cat1}\", fontsize=10)\n",
    "    ax.set_xlabel(cat1)\n",
    "    ax.set_ylabel(\"Percent\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "    ax.legend(title=cat2, bbox_to_anchor=(1.05, 1), fontsize=8)\n",
    "\n",
    "# Hide unused axes if any\n",
    "for ax in axes[len(pairings):]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**\n",
    "- Cars from Ford and Opel are predominantly manual and petrol-fueled -> likely older and more affordable models\n",
    "- Manual transmission cars are primarily petrol-fueled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Cramér's V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cramér’s V** is a statistical measure that quantifies how strongly two **categorical variables** are associated: The higher the value, the higher the association.\n",
    "\n",
    "- It is based on the **Chi-square (χ²) statistic**, which compares the **observed frequencies** in a contingency table to the **expected frequencies** (if the variables were independent).  \n",
    "- Cramér’s V normalizes this χ² value to produce a result **between 0 and 1**, making it easy to interpret.\n",
    "\n",
    "\\[\n",
    "V = \\sqrt{\\frac{\\chi^2}{n \\times (k - 1)}}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- **χ²** = Chi-square statistic from the contingency table  \n",
    "- **n** = total number of observations  \n",
    "- **k** = smaller of (number of rows, number of columns)\n",
    "\n",
    "**Key Points**\n",
    "- Symmetric: same result whether you swap the variables.  \n",
    "- Works only for **categorical–categorical** relationships.  \n",
    "- Does **not** tell the *direction* of association (only strength).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cramér's V for categorical features\n",
    "def cramers_v(x, y):\n",
    "    tbl = pd.crosstab(x, y)\n",
    "    if tbl.shape[0] < 2 or tbl.shape[1] < 2:\n",
    "        return np.nan\n",
    "    chi2 = chi2_contingency(tbl, correction=False)[0]\n",
    "    n = tbl.values.sum()\n",
    "    r, k = tbl.shape\n",
    "    phi2 = chi2 / n\n",
    "    # bias correction\n",
    "    phi2_corr = max(0, phi2 - (k - 1)*(r - 1)/(n - 1))\n",
    "    r_corr = r - (r - 1)**2/(n - 1)\n",
    "    k_corr = k - (k - 1)**2/(n - 1)\n",
    "    denom = max((k_corr - 1), (r_corr - 1))\n",
    "    return np.sqrt(phi2_corr / denom) if denom > 0 else np.nan\n",
    "\n",
    "if len(cat_cols) > 1:\n",
    "    m = pd.DataFrame(index=cat_cols, columns=cat_cols, dtype=float)\n",
    "\n",
    "    for a in cat_cols:\n",
    "        for b in cat_cols:\n",
    "            if a == b:\n",
    "                m.loc[a, b] = 1.0\n",
    "            else:\n",
    "                m.loc[a, b] = cramers_v(df_cars_train_cleaned[a], df_cars_train_cleaned[b])\n",
    "\n",
    "    plt.figure(figsize=(min(0.7 * len(cat_cols) + 5, 14),\n",
    "                        min(0.7 * len(cat_cols) + 5, 14)))\n",
    "\n",
    "    sns.heatmap(\n",
    "        m.astype(float),\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap=\"vlag\",\n",
    "        vmin=0, vmax=1,\n",
    "        linewidths=.5,\n",
    "        annot_kws={\"size\": 10},\n",
    "        alpha=0.65,\n",
    "        cbar_kws={\"shrink\": 0.85}\n",
    "    )\n",
    "\n",
    "    plt.title(\"Cramér's V — categorical features\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough categorical features for Cramér's V.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**\n",
    "- The strongest but still only weak association is between **brand and model** (0.27) which makes sense but the low value suggests that there are many models for each brand, so knowing the brand doesn't perfectly predict the model.\n",
    "\n",
    "The other associations are too weak and not directly related to our target variable (price) so not worth mentioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some 3-dimensional analysis regarding specific relationships with the target variable (price)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~J"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "exploratory_data_analysis",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
