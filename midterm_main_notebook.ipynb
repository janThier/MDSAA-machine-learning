{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52359b17-1216-4744-a528-81e23a033a68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27fff3e4-624f-4b1f-b258-fbbe7b69cb00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Import & load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "aa35af5d-8257-4fb6-a380-86bbbfac3244",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "556ffc24-70f7-48c9-96a4-3a19380f91db",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Kaggle Connect"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Folder containing kaggle.json\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = \"/Workspace/Users/20250355@novaims.unl.pt\"\n",
    "\n",
    "# Optional: test\n",
    "!echo $KAGGLE_CONFIG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f54ab11e-fcfc-4278-8997-89a92adf8eff",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import and load Data"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE, chi2\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, FunctionTransformer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import Ridge, Lasso, LassoCV, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor, StackingRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from data_cleaning import clean_car_dataframe\n",
    "\n",
    "df_cars_train = pd.read_csv(\"train.csv\")\n",
    "df_cars_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "228971f7-84d2-4472-84d1-f4b91e185bbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Explorative Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b65f0ae-0d7a-4cdb-830a-391a209b82d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "TASK I (3 Points): Descriptive Statistics, Inconsistency Check, Visual Data Explorance, Extraction of Relevant Insights, Multivariate Relationships  => Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b60f640e-1c37-401c-bce1-290392e2be9a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Exploratory Data Analysis"
    }
   },
   "outputs": [],
   "source": [
    "df_cars_train.describe(include=\"all\").T\n",
    "\n",
    "# Findings:\n",
    "# column carID has no duplicates\n",
    "# column year: 1970 to 2024\n",
    "# column mileage: -58.000 to 323.000 \n",
    "# column tax: -91 to 580\n",
    "# column mpg: -43 to 470 \n",
    "# column engineSize: -0.1 to 6.6 \n",
    "# column paintQuality%: 70-100, few outliers 1.6 or 125  \n",
    "# column previousOwners: -2.3 to 6.2 \n",
    "# column hasDamage (0/nan, not sure if nan means damaged, convert to Int)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b75ee214-0996-406f-b77f-9e72fa7153e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Cleaning, Feature Engineering, Split & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b78e7ca8-ba25-4ea3-873d-4f3515281440",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Task II (5 Points): Clean and preprocess the dataset. \n",
    "- Missing Value handling, Outlier preprocessing + justify decisions -> in data_cleaning.py\n",
    "- Review current features and create extra features if needed + explain\n",
    "- Deal with categorical variables -> One-Hot-Encoding \n",
    "- Perform data scaling, explain reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6fa0cfe9-be7e-4e90-ac1c-cd600bb7d13f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Numerical / Categorical Data Cleaning: with Pandas"
    }
   },
   "outputs": [],
   "source": [
    "# Outlier Preprocessing happens here\n",
    "df_cars_train = clean_car_dataframe(df_cars_train)\n",
    "df_cars_test = clean_car_dataframe(df_cars_test)\n",
    "\n",
    "\n",
    "# Safety Check: print all unique values of all columns of df_cars_train // df_cars_test to see if data cleaning worked and if there are still weird values\n",
    "for col in df_cars_train.columns:\n",
    "    print(col, df_cars_train[col].unique())\n",
    "print(\"X\"*150)\n",
    "for col in df_cars_test.columns:\n",
    "    print(col, df_cars_test[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2df7bf7c-0ebb-4f4b-a168-5b2e2f6b21d6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Feature Engineering"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Engineering and Explaination\n",
    "\n",
    "# add column age: models can easier interpret linear numerical features\n",
    "df_cars_train['age'] = 2025 - df_cars_train['year']\n",
    "df_cars_test['age'] = 2025 - df_cars_test['year']\n",
    "\n",
    "# miles per year: normalizes the total mileage by how old the car is\n",
    "df_cars_train['miles_per_year'] = df_cars_train['mileage'] / df_cars_train['age'].replace({0: np.nan})\n",
    "df_cars_train['miles_per_year'] = df_cars_train['miles_per_year'].fillna(df_cars_train['mileage'])\n",
    "\n",
    "df_cars_test['miles_per_year'] = df_cars_test['mileage'] / df_cars_test['age'].replace({0: np.nan})\n",
    "df_cars_test['miles_per_year'] = df_cars_test['miles_per_year'].fillna(df_cars_test['mileage'])\n",
    "\n",
    "# model frequency: some models are more common, which means they can be cheaper (supply) or retain their values better (demand). freq shows their popularity\n",
    "model_freq = df_cars_train['model'].value_counts(normalize=True).to_dict()\n",
    "df_cars_train['model_freq'] = df_cars_train['model'].map(model_freq)\n",
    "\n",
    "model_freq = df_cars_test['model'].value_counts(normalize=True).to_dict()\n",
    "df_cars_test['model_freq'] = df_cars_test['model'].map(model_freq)\n",
    "\n",
    "# brand median price (only train): shows brand positioning (e.g. BMW > KIA)\n",
    "brand_median_price = df_cars_train.groupby('Brand')['price'].median()\n",
    "df_cars_train['brand_med_price'] = df_cars_train['Brand'].map(brand_median_price)\n",
    "\n",
    "# model median price (only train): shows model positioning (e.g. 3er > 1er)\n",
    "model_med_price = df_cars_train.groupby('model')['price'].median()\n",
    "df_cars_train['model_med_price'] = df_cars_train['model'].map(model_med_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "dda482e9-4a68-438d-86c0-e0524a9b8692",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Split Data"
    }
   },
   "outputs": [],
   "source": [
    "X = df_cars_train.drop(columns='price')\n",
    "y = df_cars_train['price']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size = 0.3, \n",
    "                                                  random_state = 42, \n",
    "                                                  #stratify = y,    # if y, class proportions get preserved between train and test sets\n",
    "                                                  shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "39142374-d485-42e7-a6cb-83ecffae0091",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Preprocessing: with sklearn Pipeline & Column Transformer"
    }
   },
   "outputs": [],
   "source": [
    "# Define which columns are numeric vs categorical (mileage not in here because skewed - log)\n",
    "numeric_features = [\"age\", \"tax\", \"mpg\", \"engineSize\", \"paintQuality\", \"previousOwners\"]\n",
    "log_features = [\"mileage\", \"miles_per_year\", \"model_freq\", \"brand_med_price\", \"model_med_price\"] # could try to test previousOwners, tax, age here\n",
    "categorical_features = [\"Brand\", \"model\", \"transmission\", \"fuelType\"]\n",
    "\n",
    "# left out columns: year (age is better), hasDamage (unsure what the two values 0 and NaN mean)\n",
    "\n",
    "\n",
    "log_transformer = Pipeline([\n",
    "    # Handling of missing numerical values with sklearn SimpleImputer (mean)\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    # Data Scaling with sklearn FunctionTransformer (for log) and StandardScaler\n",
    "    (\"log\", FunctionTransformer(np.log1p, validate=False)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    # Handling of missing numerical values with sklearn SimpleImputer (mean)\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    # Data Scaling with sklearn StandardScaler\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    # Handling of missing categorical values with sklearn SimpleImputer (Unknown)\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "    # Deal with Categorical Variables with sklearn OneHotEncoder:\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)) \n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    # Apply the preprocessing steps to the data\n",
    "    (\"mileage\", log_transformer, [\"mileage\"]), # log because mileage is skewed\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "], remainder=\"drop\")\n",
    "\n",
    "\n",
    "# Fit preprocessor on training data - avoid data leakage\n",
    "preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba8f763f-298d-444a-80a9-0270ba842dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71e9a293-7457-4767-8a26-7c930f7dbad8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Task III (3 Points): Define and Implement a clear and unambiguous strategy for feature selection. Use the methods discussed in the course. Present and justify your final selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d989a4b-077d-47bd-b4bb-c4528628888f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Model independent Filter Methods:\n",
    "- Remove constant numerical variables with VarianceThreshold (manual)\n",
    "- Check highly correlated numerical variables and keep one with Spearman (manual)\n",
    "- Remove unindependent categorical variables with Chi2\n",
    "\n",
    "Model dependent Wrapper Methods:\n",
    "- RFE LR / RFE SVR for linear Models: Ridge, Lasso, ElasticNet, SVM\n",
    "- Feature Importance for tree Models: DecisionTrees, RandomForest, GradientBoosting => trees are unsensitive to irrelevant features but doing feature importance and remove some can reduce dimensionality\n",
    "- L1 Regularization for Neural Networks: MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "130e5929-dcd7-48db-8afa-8f9f560968fe",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Feature Selection with Filter Methods"
    }
   },
   "outputs": [],
   "source": [
    "X_train_proc = preprocessor.transform(X_train)\n",
    "\n",
    "feature_names_all = []\n",
    "for name, trans, cols in preprocessor.transformers_:\n",
    "    if name != 'remainder':\n",
    "        if hasattr(trans, 'get_feature_names_out'):\n",
    "            # for categorical OHE\n",
    "            try:\n",
    "                feature_names_all.extend(trans.get_feature_names_out(cols))\n",
    "            except:\n",
    "                feature_names_all.extend(cols)\n",
    "        else:\n",
    "            feature_names_all.extend(cols)\n",
    "\n",
    "X_df = pd.DataFrame(X_train_proc, columns=feature_names_all)\n",
    "\n",
    "\n",
    "# Variance Threshold\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "vt.fit(X_df)\n",
    "vt_deselect = [f for f, keep in zip(feature_names_all, vt.get_support()) if not keep]\n",
    "print(\"Features to deselect according to VarianceThreshold:\", vt_deselect)\n",
    "\n",
    "\n",
    "# Spearman correlation (numeric + log only)\n",
    "numeric_log = numeric_features + log_features\n",
    "spearman_deselect = []\n",
    "for f in numeric_log:\n",
    "    if f in X_df.columns:\n",
    "        corr, _ = spearmanr(X_df[f], y_train)\n",
    "        if abs(corr) <= 0.05:\n",
    "            spearman_deselect.append(f)\n",
    "print(\"Features to deselect according to Spearman correlation:\", spearman_deselect)\n",
    "\n",
    "\n",
    "# Chi2 (categorical only, must be non-negative)\n",
    "cat_cols = [c for c in X_df.columns if c not in numeric_log]\n",
    "X_cat = X_df[cat_cols].astype(float)\n",
    "chi2_vals, _ = chi2(X_cat, y_train)\n",
    "chi2_deselect = [f for f, val in zip(cat_cols, chi2_vals) if val <= 0]\n",
    "print(\"Features to deselect according to ChiÂ²:\", chi2_deselect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d62d3f6a-baa5-40e9-913a-b99f443b5080",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Feature Deselection for linear Models"
    }
   },
   "outputs": [],
   "source": [
    "# Numeric/log features for linear models\n",
    "linear_numeric_features = [f for f in numeric_features + log_features if f not in spearman_deselect]\n",
    "\n",
    "preprocessor_linear = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, linear_numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "], remainder=\"drop\")\n",
    "\n",
    "# => use preprocessor_linear for linear model setup; since tree models are indifferent to irrelevant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6dcae03f-ed97-410e-9078-fb734f42be87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Models Setup and Baselining (with SKLEARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06207ec2-af0d-489f-a23d-467019791499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "TASK IV (4 Points): Build a simple model and assess the performance\n",
    "- Identify the type of problem and select the relevant algorithms\n",
    "- Select one Model Assessment Strategy to use throughout your work. Which metrics are you using to evaluate your model and why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6297f034-638d-4db6-a681-597f20036432",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Definition of Function for Model Assessment"
    }
   },
   "outputs": [],
   "source": [
    "# Following metrics are used for model evaluation:\n",
    "#\n",
    "#   MAE: Average absolute deviation between predicted and true car prices, easy to interpret, kaggle competition uses same metric\n",
    "#   RMSE: Root mean squared error, helps to see if large errors on same values were made, therefore sensitive to outliers\n",
    "#   R2: Proportion of variance explained by the model, 1 = perfect, 0 = same as predicting mean, < 0 = worse than mean baseline\n",
    "#\n",
    "# Because our task is a regression problem and we are predicting a continuous variable (car price)\n",
    "\n",
    "def print_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"MAE: {mae:.4f} | RMSE: {rmse:.4f} | R2: {r2:.4f}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "04d3aa5b-36ca-4dba-9592-24edd345897d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Models Setup (inkl. Prepro in Pipeline)"
    }
   },
   "outputs": [],
   "source": [
    "### LINEAR MODEL\n",
    "# ElasticNet\n",
    "elastic_pipe = Pipeline([\n",
    "    (\"preprocess\", preprocessor_linear),\n",
    "    (\"model\", ElasticNet(\n",
    "        max_iter=20000,\n",
    "        selection=\"random\",\n",
    "        warm_start=False,  # set True only if iteratively tuning manually\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "### TREE MODELS\n",
    "# HistGradientBoostingRegressor: modern and very fast, handles missing values natively (no imputation needed!). often matches or beats XGBoost/LightGBM \n",
    "hgb_pipe = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", HistGradientBoostingRegressor(\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        n_iter_no_change=20,\n",
    "        l2_regularization=0.5,  # regularize slightly to prevent overfit, try 0.1, 0.5, 1.0\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "5b26348e-a5ff-4dc9-9d61-7f59d0ea335d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Baselining mean/median"
    }
   },
   "outputs": [],
   "source": [
    "mean_pred = y_train.mean()\n",
    "median_pred = y_train.median()\n",
    "\n",
    "print(\"baseline mean predictor: \")\n",
    "print_metrics(y_val, [mean_pred]*len(y_val))\n",
    "# MAE: 6976.3626 | RMSE: 92839550.2849 | R2: -0.0000\n",
    "\n",
    "print(\"-\"*150)\n",
    "\n",
    "print(\"baseline median predictor: \") \n",
    "print_metrics(y_val, [median_pred]*len(y_val))\n",
    "# MAE: 6751.1604 | RMSE: 97557866.6363 | R2: -0.0508"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54cc12b6-a13e-42b2-82bc-eb50b8871586",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "18042056-7ef9-489f-afc3-958fe02fbfc0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Hyperparameter Tuning: ElasticNet"
    }
   },
   "outputs": [],
   "source": [
    "elastic_param_grid = {\n",
    "    \"model__alpha\": [0.001, 0.01, 0.05, 0.1, 0.5],\n",
    "    \"model__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9]     \n",
    "}\n",
    "\n",
    "elastic_grid = GridSearchCV(\n",
    "    elastic_pipe, \n",
    "    param_grid=elastic_param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "elastic_grid.fit(X_train, y_train)\n",
    "elastic_best = elastic_grid.best_estimator_\n",
    "elastic_val_pred = elastic_best.predict(X_val)\n",
    "\n",
    "\n",
    "print(\"ElasticNet Results: \")\n",
    "print_metrics(y_val, elastic_val_pred)\n",
    "print(\"Best ElasticNet params:\", elastic_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "78157989-9ef4-4b2b-a9e1-72309a89e754",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Hyperparameter Tuning: HistGradientBoost"
    }
   },
   "outputs": [],
   "source": [
    "hgb_param_grid = {\n",
    "    \"model__learning_rate\": [0.07], # also tried: 0.02, 0.04, 0.06, 0.1\n",
    "    \"model__max_leaf_nodes\": [60], # also tried: 15, 25, 31, 50\n",
    "    \"model__min_samples_leaf\": [8], # also tried: 5, 10, 15, 20\n",
    "    \"model__max_iter\": [1000] # also tried: 500, 800\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "hgb_grid = GridSearchCV(\n",
    "    estimator=hgb_pipe,\n",
    "    param_grid=hgb_param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_mean_absolute_error\",  # optimize MAE\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "hgb_grid.fit(X_train, y_train)\n",
    "hgb_best_1 = hgb_grid.best_estimator_\n",
    "\n",
    "hgb_val_pred = hgb_best_1.predict(X_val)\n",
    "print_metrics(y_val, hgb_val_pred)\n",
    "\n",
    "# Best Parameters: {'model__learning_rate': 0.06, 'model__max_iter': 800, 'model__max_leaf_nodes': 50, 'model__min_samples_leaf': 5}\n",
    "# MAE: 1304.7611 | RMSE: 4503446.5247 | R2: 0.9515\n",
    "\n",
    "# Save model for later use\n",
    "joblib.dump(hgb_best_1, \"hgb_best_1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "135acfad-1ad6-49f9-97fc-f1a81d0c3187",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb68e758-d7b1-4f80-9dc4-ed985f721c45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Extra Task (1 Point): Be in the Top 5 Groups on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "927be871-4f27-4453-baac-b4f7102534d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load hgb_best_1 from joblib\n",
    "hgb_best_1 = joblib.load(\"hgb_best_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6a25f58c-4c24-4460-93d4-830176016ee8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Pick best Model, predict on Test"
    }
   },
   "outputs": [],
   "source": [
    "# Pick best model and predict on test:\n",
    "df_cars_test['price'] = hgb_best_1.predict(df_cars_test)\n",
    "\n",
    "df_cars_test['price'].to_csv('submission.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f5b18805-e662-4807-bdb8-758df6027d1b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Kaggle Submission with API push"
    }
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c cars4you -f submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "350057a3-c771-4bf0-8fac-19b49be17e35",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Kaggle Score Check"
    }
   },
   "outputs": [],
   "source": [
    "# Kaggle Score Check\n",
    "!kaggle competitions submissions -c cars4you"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "midterm_main_notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
