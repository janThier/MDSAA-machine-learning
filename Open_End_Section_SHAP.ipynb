{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6df97636-355b-48e4-9c26-f188a4eb8029",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "!pip install shap\n",
    "!pip install -U scikit-learn\n",
    "!pip install category_encoders\n",
    "!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f54ab11e-fcfc-4278-8997-89a92adf8eff",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import and load Data"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    " \n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, TargetEncoder, StandardScaler, FunctionTransformer, RobustScaler\n",
    "from category_encoders import QuantileEncoder\n",
    "from category_encoders.wrapper import NestedCVWrapper\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    " \n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor, StackingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcParams.update({\"figure.max_open_warning\": 0, \"figure.dpi\": 100})\n",
    "import shap\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "from pipeline_functions import CarDataCleaner, IndividualHierarchyImputer, CarFeatureEngineer, DebugTransformer, MajorityVoteSelectorTransformer, MutualInfoThresholdSelector, SpearmanRelevancyRedundancySelector, create_model_pipe, get_cv_results, model_hyperparameter_tuning, SetOutputCompatibleWrapper\n",
    "from visualization_functions import plot_selector_agreement, plot_train_val_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "375bef87-944e-4bc0-bb70-727575f55635",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "et_tuned_pipe = joblib.load(\"rf_tuned_pipe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7635b5e1-9e97-41d2-b598-1d9958fbc39e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "debug_preprocessor_pipe = joblib.load(\"debug_preprocessor_pipe.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7bfd1b4a-0e13-443a-aeb7-fa6324f801e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 10. Open-Ended-Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ec41562-43a9-4f5c-926b-87a030817982",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 10.1 SHAP Interpretability for Our Final Tree Model (Informative Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6ab8416-e284-420e-b706-49813911001d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**a) Objective and motivation**\n",
    "\n",
    "After our end-to-end pipeline is finished, we use **SHAP (SHapley Additive exPlanations)**.\n",
    "\n",
    "Goals:\n",
    "- Identify the **most influential features** for the final tuned model (`et_tuned_pipe`).\n",
    "- Validate whether feature effects are **plausible** (age, mileage, engine, etc.).\n",
    "- Check how much **target encodings** and engineered interactions contribute.\n",
    "\n",
    "Important: **SHAP does not change the model or feature set.** We do not build a new pipeline based on SHAP.\n",
    "\n",
    "---\n",
    "\n",
    "**b) Difficulty of the task**\n",
    "\n",
    "This is non-trivial because SHAP must explain the model input **after** our preprocessing and feature selection:\n",
    "\n",
    "- The model does not see raw columns. \n",
    "It sees: engineered numeric features (e.g., interactions, relative features, logs), OHE columns, target-encoded columns and the reduced subset after **VT + majority voting**.\n",
    "- We therefore reconstruct:\n",
    "  - the exact **post-preprocess feature matrix**, and\n",
    "  - aligned **feature names** after applying both selection masks (VT support + majority selector mask).\n",
    "- Because the full pipeline includes engineered preprocessing + selection, we treat the tuned pipeline as a **black box** and use SHAP via a **PermutationExplainer** (robust but expensive).\n",
    "- Runtime: SHAP is costly, so we explain only a **subsample** (`sample_size=1000`) with a small background set.\n",
    "\n",
    "---\n",
    "\n",
    "**c) Correctness and efficiency**\n",
    "\n",
    "We kept the analysis correct and consistent with the production pipeline:\n",
    "\n",
    "- **No leakage / no optimization loop:** SHAP is computed on the already-fitted `et_tuned_pipe` and used only for interpretation.\n",
    "- **Exact alignment:** feature names come from the ColumnTransformer output and are then filtered by VT + majority voting masks.\n",
    "- **Global SHAP importance:** features are ranked by mean absolute contribution:\n",
    "  \n",
    "  $$\n",
    "  Importance(feature_j) = \\frac{1}{N}\\sum_{i=1}^{N} |SHAP_{i,j}|\n",
    "  $$\n",
    "\n",
    "- **Efficient computation:** stable ranking via subsampling (PermutationExplainer on 1000 rows; runtime ~21 minutes in our run).\n",
    "\n",
    "---\n",
    "\n",
    "**d) Results and interpretation**\n",
    "\n",
    "Model context:\n",
    "- Final tuned model: `et_tuned_pipe` (**ExtraTrees**)\n",
    "- Total features used after preprocessing + FS: **28**\n",
    "- SHAP explainer used: **PermutationExplainer** (1001 iterations; ~21:34 total)\n",
    "\n",
    "Top drivers (mean |SHAP|), excerpt:\n",
    "\n",
    "| Feature | Importance | Interpretation |\n",
    "|---|---:|---|\n",
    "| `mean_te__model` | 1486.36 | Model-level mean target encoding (strong market-value proxy) |\n",
    "| `median_te__model` | 1409.38 | Model-level median target encoding (strong market-value proxy) |\n",
    "| `num__mpg_x_age` | 870.81 | Interaction capturing “efficiency x age” effects |\n",
    "| `cat__transmission_Manual` | 846.46 | Manual transmission effect (dataset-dependent) |\n",
    "| `num__age` | 764.79 | Direct age penalty / depreciation signal |\n",
    "| `num__engineSize` | 655.15 | Engine size (segment/performance proxy) |\n",
    "| `num__age_rel_brand` | 628.79 | Age relative to typical age inside the brand |\n",
    "| `log__mileage` | 592.53 | Non-linear mileage effect (diminishing marginal impact) |\n",
    "| `median_te__brand_trans` | 521.83 | Brand x transmission median target encoding |\n",
    "| `num__age_rel_model` | 488.77 | Age relative to typical age within the model |\n",
    "| `num__engine_per_mpg` | 303.93 | Performance/efficiency ratio proxy |\n",
    "| `log__miles_per_year` | 223.94 | Usage intensity (mileage normalized by age) |\n",
    "\n",
    "Key takeaways:\n",
    "- **Target encodings still dominate** global importance (model-level mean/median TE). This is expected: model identity carries a large fraction of price signal.\n",
    "- **Transmission became a top driver** in the ExtraTrees variant (`cat__transmission_Manual` ranks #4), suggesting stronger split usage on this categorical signal compared to the previous RF run.\n",
    "- **Age and mileage remain major drivers**, and appear in intuitive forms (`num__age`, `log__mileage`, relative age features, and `log__miles_per_year`), supporting interpretability.\n",
    "- **Engine/performance interactions matter** (`num__engineSize`, `num__engine_per_mpg`, `num__mpg_x_age`, `num__mpg_x_engine`), indicating feature engineering adds useful non-linear structure beyond raw variables.\n",
    "\n",
    "Beeswarm plot (distribution of effects), main observations:\n",
    "- **`mean_te__model` and `median_te__model` show the widest SHAP spread** → model identity (via target encoding) is the strongest pricing signal.\n",
    "- **Manual transmission shows a clear directional pattern** in this tuned ExtraTrees model: `cat__transmission_Manual=1` tends to push predictions **down** (negative SHAP), while `=0` tends to push them **up** (positive SHAP), with heterogeneity explained by brand/model interactions.\n",
    "- **Mileage is clearly non-linear** (`log__mileage`): low mileage contributes positively; high mileage pushes predictions down with diminishing marginal impact.\n",
    "- **Age effects are consistent** (`num__age`, `num__age_rel_brand`, `num__age_rel_model`): being older (especially older than “typical” for brand/model) reduces predicted price.\n",
    "\n",
    "---\n",
    "\n",
    "**e) Alignment with objectives**\n",
    "\n",
    "This section adds transparency without changing the modeling procedure:\n",
    "\n",
    "- Feature selection stays **VT + majority voting** (robust and model-agnostic).\n",
    "- SHAP is used **only** to explain the final tuned model (`et_tuned_pipe`).\n",
    "- The resulting drivers (target encodings + age/mileage/engine + interactions + transmission) are consistent with domain logic and support trust in the final pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14e95284-b5e6-4bc5-bed0-dcbd0bc08895",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e482273-1672-43c3-85da-021bab9a6730",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get Feature names aligned with X_proc (after preprocess incl. VT + majority voting)\n",
    "def get_pipeline_feature_matrix(pipe, X, debug_preprocessor_pipe):\n",
    "    \"\"\"\n",
    "    Given a fitted model pipeline with steps:\n",
    "      'preprocess' -> 'model'\n",
    "    where preprocess itself is a Pipeline:\n",
    "      clean -> group_imputer -> fe -> ct -> fs(vt + selector)\n",
    "    return:\n",
    "      X_proc: 2D numpy array of features just before the model step\n",
    "      feat_names: 1D np.array of feature names aligned with X_proc columns\n",
    "    \"\"\"\n",
    "    pre = pipe.named_steps[\"preprocess\"]\n",
    "\n",
    "    # Transform to model-ready matrix and get feature names debug preprocessor\n",
    "    X_proc = pre.transform(X)\n",
    "    feat_names = debug_preprocessor_pipe.named_steps['fs'].get_feature_names_out()\n",
    "\n",
    "    return X_proc, feat_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "376efbe1-3436-4902-bf58-e6d72d8ec213",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compute SHAP Importance\n",
    "def compute_shap_importance(\n",
    "    pipe,\n",
    "    X,\n",
    "    sample_size=1000,\n",
    "    seed=rs,\n",
    "    model_name=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute global SHAP feature importances for a fitted pipeline (informative only).\n",
    "\n",
    "    Fix:\n",
    "      - TreeExplainer additivity check can fail for some sklearn tree implementations (incl. HGB).\n",
    "        We disable it via check_additivity=False.\n",
    "      - If TreeExplainer still fails, fall back to a model-agnostic SHAP explainer.\n",
    "    \"\"\"\n",
    "    # Extract processed feature matrix and names\n",
    "    X_proc, feat_names = get_pipeline_feature_matrix(pipe, X, debug_preprocessor_pipe)\n",
    "\n",
    "    # Subsample rows for SHAP (for speed)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = min(sample_size, len(X_proc))\n",
    "    idx = rng.choice(len(X_proc), n, replace=False)\n",
    "    X_sample = X_proc[idx]\n",
    "\n",
    "    # Underlying model (last step in pipeline)\n",
    "    model = pipe.named_steps[\"model\"]\n",
    "    tag = model_name or model.__class__.__name__\n",
    "\n",
    "    # Background for SHAP (small subset)\n",
    "    bg_n = min(200, len(X_sample))\n",
    "    bg_idx = rng.choice(len(X_sample), bg_n, replace=False)\n",
    "    X_bg = X_sample[bg_idx]\n",
    "\n",
    "    # Try TreeExplainer first (fast for tree models)\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(model, X_bg)\n",
    "        shap_vals = explainer.shap_values(X_sample, check_additivity=False)\n",
    "\n",
    "        # shap_vals can be list-like in some setups; regression should be 2D\n",
    "        if isinstance(shap_vals, list):\n",
    "            shap_vals = shap_vals[0]\n",
    "\n",
    "        base_vals = getattr(explainer, \"expected_value\", 0.0)\n",
    "        shap_values = shap.Explanation(\n",
    "            values=shap_vals,\n",
    "            base_values=np.full((len(X_sample),), base_vals) if np.isscalar(base_vals) else base_vals,\n",
    "            data=X_sample,\n",
    "            feature_names=feat_names,\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        # Fallback: model-agnostic explainer (slower but robust)\n",
    "        explainer = shap.Explainer(model.predict, X_bg, feature_names=feat_names)\n",
    "        shap_values = explainer(X_sample)\n",
    "\n",
    "    importance = np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "    shap_df = (\n",
    "        pd.DataFrame({\"feature\": feat_names, \"importance\": importance})\n",
    "        .sort_values(\"importance\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(f\"Features by SHAP for {tag}:\")\n",
    "    print(shap_df.head(40).to_string(index=False))\n",
    "\n",
    "    return shap_df, feat_names, shap_values, X_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b60df542-e409-4e40-9e0d-88b89df8ee79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SHAP Plots\n",
    "def plot_top_shap_bar(shap_df, model_name, top_k):\n",
    "    \"\"\"\n",
    "    Horizontal bar plot of top_k features by mean |SHAP|.\n",
    "    \"\"\"\n",
    "    top_df = shap_df.head(top_k).iloc[::-1]  # reverse for nicer barh order\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.barh(top_df[\"feature\"], top_df[\"importance\"])\n",
    "    ax.set_xlabel(\"Average |SHAP| value\")\n",
    "    ax.set_title(f\"Top {top_k} features by SHAP – {model_name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_shap_beeswarm(shap_values, X_sample, feat_names, model_name, max_display=20):\n",
    "    \"\"\"\n",
    "    SHAP summary (beeswarm) plot for top features.\n",
    "    \"\"\"\n",
    "    X_df = pd.DataFrame(X_sample, columns=feat_names)\n",
    "\n",
    "    # Create one figure and tell SHAP not to auto-show\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values.values, X_df, max_display=max_display, show=False)\n",
    "\n",
    "    plt.title(f\"SHAP Beeswarm – {model_name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e9d6767-48ad-4d33-b40b-49861baeb6b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### SHAP of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aef535f9-31ab-455c-9fba-1ff8631f4de3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ExtraTrees baseline report + SHAP\n",
    "et_pipe = et_tuned_pipe\n",
    "\n",
    "# Feature matrix + names after preprocess (clean+impute+fe+ct+fs)\n",
    "X_proc_et, feat_names_et = get_pipeline_feature_matrix(et_pipe, X_train, debug_preprocessor_pipe)\n",
    "n_features_total_et = X_proc_et.shape[1]\n",
    "\n",
    "print(\"ExtraTrees (tuned pipe) - feature space info:\")\n",
    "print(f\"Total features used: {n_features_total_et}\")\n",
    "\n",
    "shap_importance_et, feat_names_et, shap_vals_et, X_sample_et = compute_shap_importance(\n",
    "    et_pipe,\n",
    "    X_train,\n",
    "    sample_size=1000,\n",
    "    seed=rs,\n",
    "    model_name=\"ExtraTrees\",\n",
    ")\n",
    "\n",
    "plot_top_shap_bar(shap_importance_et, model_name=\"ExtraTrees\", top_k=n_features_total_et)\n",
    "plot_shap_beeswarm(shap_vals_et, X_sample_et, feat_names_et, model_name=\"ExtraTrees\", max_display=n_features_total_et)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "841d23d9-3047-4221-8aa2-709808ebcfe5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 10.2 Global vs Brand- and Model-Specific Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1542217-ddec-4f10-a902-3873f1871bca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**a) Objective and motivation**\n",
    "\n",
    "We investigated how far Cars4You should specialize its pricing models:\n",
    "\n",
    "1. **Brand level:** Is a single global price model sufficient, or do brand-specific models reduce pricing error?\n",
    "2. **Brand–model level:** For frequent (brand, model) segments (e.g. “VW Golf”, “Skoda Octavia”), does an even more specialized model per segment bring additional improvements, or does it overfit?\n",
    "\n",
    "Starting point is our final tuned production pipeline **`et_tuned_pipe`** (full preprocessing + tuned **ExtraTrees** regressor). We compare:\n",
    "\n",
    "- **Global model:** trained on all cars, evaluated only on a given segment.\n",
    "- **Brand-specific model:** same pipeline structure and hyperparameters, fitted only on cars of a given brand.\n",
    "- **Brand–model-specific model:** same pipeline structure and hyperparameters, fitted only on cars of a given (brand, model) pair.\n",
    "\n",
    "We measured **MAE** and **RMSE** per segment using **5-fold cross-validation**. This quantifies the gain/loss when moving from:\n",
    "\n",
    "> one global model → several brand models → many brand–model models.\n",
    "\n",
    "---\n",
    "\n",
    "**b) Difficulty of the tasks**\n",
    "\n",
    "This multi-level comparison is not easy because it requires leakage-free, segment-wise evaluation inside cross-validation:\n",
    "\n",
    "- **Per-segment metrics inside CV (not a single score):** each fold must report MAE/RMSE *for specific brands/pairs* on the fold’s validation set.\n",
    "- **Fair protocol for global vs specialized models (within each fold):**\n",
    "  - global model is trained on all training rows, but evaluated only on validation rows belonging to the segment;\n",
    "  - segment-specific model is trained and evaluated only on that segment’s rows.\n",
    "- **Imbalanced / small segments:** data is heavily skewed across brands/models, so we enforce minimum segment sizes:\n",
    "  - **brand level:** only brands with **≥ 500** samples overall;\n",
    "  - **brand–model level:** only pairs with **≥ 80** samples overall;\n",
    "  - plus per-fold minimum training-size checks to avoid unstable tiny fits.\n",
    "- **Cleaning labels before grouping:** inconsistent text labels (casing/spacing/typos) can split real segments; we normalize `(brand, model)` once using the same cleaning logic as in the pipeline and use cleaned labels for masks.\n",
    "- **Manual RMSE:** computed as `sqrt(MSE)` inside the CV loops for compatibility with our environment.\n",
    "\n",
    "---\n",
    "\n",
    "**c) Correctness and efficiency of implementation**\n",
    "\n",
    "We kept the evaluation correct and efficient:\n",
    "\n",
    "- **Leakage-free out-of-fold evaluation:** in each fold the pipeline is fitted only on that fold’s training rows; metrics are computed only on validation rows.\n",
    "- **Single CV design reused everywhere:** identical KFold splits (`n_splits=5`, `shuffle=True`, fixed `random_state`) are reused for all comparisons, making deltas directly comparable.\n",
    "- **Efficient global baseline:** the global model is fitted **once per fold**, then reused to compute metrics for many brands/pairs in that fold (instead of refitting per segment).\n",
    "- **Segmentation labels separated from training data:** model training always uses the original fold rows; segment membership uses cleaned labels for correct grouping.\n",
    "- **Guards for tiny segments:** segments/folds with insufficient training samples are skipped to avoid unstable conclusions.\n",
    "\n",
    "---\n",
    "\n",
    "**d) Discussion of results**\n",
    "\n",
    "- **Candidate brands:** all brands\n",
    "- **Candidate (brand, model) pairs:** ≥ 80 samples; 100 pairs\n",
    "\n",
    "\n",
    "**Brand-level comparison (global vs brand-specific, using `et_tuned_pipe`)**\n",
    "\n",
    "Across the main brands, brand-specific training is **not consistently beneficial**. Even when some brands can improve, the typical trade-off remains:\n",
    "\n",
    "- **Potential benefit:** brand-specific models can capture brand-local price structure if it differs materially from the full population.\n",
    "- **Common downside:** less data and reduced diversity often outweigh specialization; the global model already captures brand effects via features (including encodings), so restricting to one brand can hurt generalization.\n",
    "- **Practical interpretation:** brand-level specialization should be treated as **optional** and justified only when it shows **stable negative ΔMAE/ΔRMSE** in CV.\n",
    "\n",
    "*(Brand-level table is omitted here because the provided updated results focus on candidate selection and pair-level outcomes; the recommendation below reflects the updated ExtraTrees pipeline behavior and the observed specialization risk patterns.)*\n",
    "\n",
    "\n",
    "**Brand–model comparison (global vs brand–model-specific, `et_tuned_pipe`)**\n",
    "\n",
    "Results are clearly **mixed** even after filtering to pairs with ≥ 80 samples: some segments improve, while others degrade substantially.\n",
    "\n",
    "**Top improvements (largest negative ΔMAE; specialized better than global):**\n",
    "\n",
    "| (brand, model) | n | MAE_global | MAE_pair | ΔMAE | RMSE_global | RMSE_pair | ΔRMSE |\n",
    "|---|---:|---:|---:|---:|---:|---:|---:|\n",
    "| Audi q7 | 268 | 3186.8 | 3044.2 | **-142.6** | 4282.0 | 4110.4 | **-171.6** |\n",
    "| Audi tt | 222 | 1852.2 | 1723.0 | **-129.3** | 2597.2 | 2368.0 | **-229.2** |\n",
    "| Ford edge | 137 | 1106.1 | 1030.3 | **-75.7** | 1556.6 | 1420.7 | **-135.9** |\n",
    "| Hyundai ioniq | 203 | 1491.9 | 1429.6 | **-62.3** | 1921.5 | 1883.2 | **-38.2** |\n",
    "| Ford s-max | 201 | 1278.5 | 1242.4 | **-36.1** | 1684.1 | 1656.7 | **-27.3** |\n",
    "| VW sharan | 180 | 1584.9 | 1563.3 | **-21.6** | 2112.6 | 2099.1 | **-13.6** |\n",
    "| Mercedes c class | 5288 | 1904.9 | 1885.7 | **-19.3** | 2813.0 | 2867.8 | **+54.8** |\n",
    "| Skoda octavia | 1021 | 944.5 | 925.4 | **-19.1** | 1333.9 | 1307.2 | **-26.6** |\n",
    "\n",
    "Notes:\n",
    "- Several segments show **consistent wins** (negative ΔMAE and negative ΔRMSE), e.g. Audi q7/tt, Ford edge, Skoda octavia.\n",
    "- Some show a **MAE improvement but RMSE worsening** (e.g. Mercedes c class: ΔMAE < 0 but ΔRMSE > 0), which suggests fewer average errors but worse tail behavior/outliers.\n",
    "\n",
    "**Top degradations (largest positive ΔMAE; specialized worse than global):**\n",
    "\n",
    "| (brand, model) | n | MAE_global | MAE_pair | ΔMAE | RMSE_global | RMSE_pair | ΔRMSE |\n",
    "|---|---:|---:|---:|---:|---:|---:|---:|\n",
    "| Audi a_unknown | 94 | 2099.5 | 2705.5 | **+606.1** | 2832.7 | 3498.3 | **+665.7** |\n",
    "| Mercedes s class | 134 | 3986.0 | 4469.3 | **+483.3** | 6122.6 | 6485.4 | **+362.8** |\n",
    "| Mercedes cls class | 160 | 1791.0 | 2175.7 | **+384.7** | 3246.5 | 3983.2 | **+736.7** |\n",
    "| VW amarok | 83 | 2326.4 | 2598.5 | **+272.1** | 3065.4 | 3424.4 | **+359.0** |\n",
    "| Mercedes gle class | 327 | 2059.5 | 2259.4 | **+199.9** | 3142.4 | 3419.7 | **+277.3** |\n",
    "| VW touareg | 244 | 2193.4 | 2367.2 | **+173.8** | 3393.5 | 3820.3 | **+426.8** |\n",
    "| Audi q5 | 594 | 1736.5 | 1903.2 | **+166.8** | 2427.5 | 2781.8 | **+354.3** |\n",
    "| BMW x5 | 313 | 2314.0 | 2476.0 | **+162.0** | 3074.4 | 3489.7 | **+415.3** |\n",
    "\n",
    "Interpretation:\n",
    "- Even with ≥ 80 samples, **pair-level specialization can overfit** and lose beneficial cross-segment learning.\n",
    "- Degradations are often large in both MAE and RMSE, indicating not just noise but materially worse generalization for some pairs.\n",
    "\n",
    "---\n",
    "\n",
    "**e) Alignment with objectives**\n",
    "\n",
    "This study directly answers whether additional specialization layers are justified for deployment under real data constraints, using the final tuned pipeline `et_tuned_pipe` and a consistent leakage-free CV protocol.\n",
    "\n",
    "**Deployment recommendation (based on ExtraTrees results and the observed Δ patterns):**\n",
    "- Keep a **single global model** as the default (most robust across segments).\n",
    "- Consider **brand-level specialization only selectively**, and only where it demonstrates **repeatable negative ΔMAE and/or ΔRMSE** under the same CV protocol.\n",
    "- Consider **brand–model specialization only as a gated option**:\n",
    "  - only for pairs with sufficient data (≥ 80 samples + per-fold minimum training size),\n",
    "  - only if the pair shows **stable negative ΔMAE and not unacceptable ΔRMSE** (watch tail risk),\n",
    "  - and with monitoring, because many pairs **degrade** substantially (positive Δ).\n",
    "\n",
    "This demonstrates not only a tuned final model, but also an evidence-based assessment of whether “more specialized” models actually improve pricing accuracy versus increasing complexity and overfitting risk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92ba9d08-ca2b-4002-9b0c-bad692630671",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 10.2.1 Load final tuned pipeline, define key columns, brand frequency and metric helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db05c68f-2a06-47dd-b700-2eb482c940da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We use the squared error here and compare it to the performance on the squared error because of disproportionate computational expensive training with the absolute_error\n",
    "pipe_template = et_tuned_pipe_squared_err\n",
    "\n",
    "# Required inputs\n",
    "brand_col = \"brand\"\n",
    "model_col = \"model\"\n",
    "\n",
    "assert brand_col in X_train.columns, f\"Missing column '{brand_col}' in X_train.\"\n",
    "assert model_col in X_train.columns, f\"Missing column '{model_col}' in X_train.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13d386c7-6b33-4765-9f14-aa84a2c80fe5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cleaner = next(v for v in pipe_template.get_params(deep=True).values()\n",
    "               if v.__class__.__name__ == \"CarDataCleaner\")\n",
    "\n",
    "X_seg = X_train.copy()\n",
    "tmp = cleaner.fit_transform(X_train.copy(), y_train)\n",
    "X_seg[[brand_col, model_col]] = tmp[[brand_col, model_col]]\n",
    "\n",
    "X_train = X_seg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fc38756-fdb4-4637-b2c4-53f698fe6dfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Inspect brand frequencies\n",
    "brand_counts = X_train[brand_col].value_counts()\n",
    "display(brand_counts.head(15).to_frame(\"count\"))\n",
    "\n",
    "\n",
    "# Select candidate brands\n",
    "#    - TOP_K: max number of brands to compare.\n",
    "#    - MIN_SAMPLES: minimum number of rows per brand.\n",
    "TOP_K = 8\n",
    "MIN_SAMPLES = 500  # ensures enough data for stable per-brand estimates\n",
    "\n",
    "candidate_brands = (\n",
    "    brand_counts[brand_counts >= MIN_SAMPLES]\n",
    "    .head(TOP_K)\n",
    "    .index\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "print(\"Candidate brands:\", candidate_brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38856080-7d48-40bf-a3b9-ce4e831b2e52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cross-validation: same folds reused everywhere for fairness and reproducibility\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "splits = list(cv.split(X_train, y_train))\n",
    "\n",
    "def mae_rmse(y_true, y_pred):\n",
    "    \"\"\"Return MAE and RMSE (RMSE computed as sqrt(MSE) for sklearn-compatibility).\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    return mae, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2192f0d-acdc-450a-b907-cceb81586bf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 10.2.2 Brand-level comparison (Global vs Brand-specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ede95d02-9d7d-4f71-beeb-7ae8a151c3f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def eval_global_by_brand(pipe_template, X, y, brand_col, brands, splits):\n",
    "    \"\"\"\n",
    "    Global model evaluation per brand (out-of-fold):\n",
    "    - Fit 1 global model per fold on ALL training rows.\n",
    "    - Compute MAE/RMSE only on validation rows belonging to each brand.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(splits, start=1):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        pipe = clone(pipe_template)\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        y_pred = pipe.predict(X_va)\n",
    "\n",
    "        for b in brands:\n",
    "            mask = (X_va[brand_col] == b)\n",
    "            n = int(mask.sum())\n",
    "            if n == 0:\n",
    "                continue\n",
    "\n",
    "            mae, rmse = mae_rmse(y_va[mask], y_pred[mask])\n",
    "            rows.append({\"fold\": fold, \"brand\": b, \"MAE\": mae, \"RMSE\": rmse, \"n\": n})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    summary = (\n",
    "        df.groupby(\"brand\")\n",
    "          .apply(lambda g: pd.Series({\n",
    "              \"MAE_mean\": g[\"MAE\"].mean(),\n",
    "              \"MAE_std\":  g[\"MAE\"].std(ddof=0),\n",
    "              \"RMSE_mean\": g[\"RMSE\"].mean(),\n",
    "              \"RMSE_std\":  g[\"RMSE\"].std(ddof=0),\n",
    "              \"n\": int(g[\"n\"].sum()),\n",
    "          }))\n",
    "          .reset_index()\n",
    "    )\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffa366d9-18c3-4e3d-80de-b1c643df89e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def eval_brand_specific(pipe_template, X, y, brand_col, brands, splits, min_train_per_fold=50):\n",
    "    \"\"\"\n",
    "    Brand-specific evaluation:\n",
    "    - For each fold and brand: train the SAME pipeline structure only on that brand's training rows.\n",
    "    - Evaluate only on that brand's validation rows.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(splits, start=1):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        for b in brands:\n",
    "            tr_mask = (X_tr[brand_col] == b)\n",
    "            va_mask = (X_va[brand_col] == b)\n",
    "\n",
    "            n_tr = int(tr_mask.sum())\n",
    "            n_va = int(va_mask.sum())\n",
    "\n",
    "            # These checks are necessary: some folds can have very few samples for a segment.\n",
    "            if n_va == 0 or n_tr < min_train_per_fold:\n",
    "                continue\n",
    "\n",
    "            pipe = clone(pipe_template)\n",
    "            pipe.fit(X_tr[tr_mask], y_tr[tr_mask])\n",
    "            y_pred_b = pipe.predict(X_va[va_mask])\n",
    "\n",
    "            mae, rmse = mae_rmse(y_va[va_mask], y_pred_b)\n",
    "            rows.append({\"fold\": fold, \"brand\": b, \"MAE\": mae, \"RMSE\": rmse, \"n\": n_va})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    summary = (\n",
    "        df.groupby(\"brand\")\n",
    "          .apply(lambda g: pd.Series({\n",
    "              \"MAE_mean\": g[\"MAE\"].mean(),\n",
    "              \"MAE_std\":  g[\"MAE\"].std(ddof=0),\n",
    "              \"RMSE_mean\": g[\"RMSE\"].mean(),\n",
    "              \"RMSE_std\":  g[\"RMSE\"].std(ddof=0),\n",
    "              \"n\": int(g[\"n\"].sum()),\n",
    "          }))\n",
    "          .reset_index()\n",
    "    )\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df5809d1-871e-4632-8db0-52b87ac9e271",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_global_brand = eval_global_by_brand(\n",
    "    pipe_template, X_train, y_train, brand_col, candidate_brands, splits\n",
    ").rename(columns={\n",
    "    \"MAE_mean\": \"MAE_mean_global\", \"MAE_std\": \"MAE_std_global\",\n",
    "    \"RMSE_mean\": \"RMSE_mean_global\", \"RMSE_std\": \"RMSE_std_global\",\n",
    "    \"n\": \"n_global\"\n",
    "})\n",
    "\n",
    "df_brand_spec = eval_brand_specific(\n",
    "    pipe_template, X_train, y_train, brand_col, candidate_brands, splits, min_train_per_fold=50\n",
    ").rename(columns={\n",
    "    \"MAE_mean\": \"MAE_mean_brand\", \"MAE_std\": \"MAE_std_brand\",\n",
    "    \"RMSE_mean\": \"RMSE_mean_brand\", \"RMSE_std\": \"RMSE_std_brand\",\n",
    "    \"n\": \"n_brand\"\n",
    "})\n",
    "\n",
    "df_compare_brand = df_global_brand.merge(df_brand_spec, on=\"brand\", how=\"inner\")\n",
    "df_compare_brand[\"delta_MAE\"] = df_compare_brand[\"MAE_mean_brand\"] - df_compare_brand[\"MAE_mean_global\"]\n",
    "df_compare_brand[\"delta_RMSE\"] = df_compare_brand[\"RMSE_mean_brand\"] - df_compare_brand[\"RMSE_mean_global\"]\n",
    "\n",
    "df_compare_brand = df_compare_brand.sort_values(\"delta_MAE\")\n",
    "display(df_compare_brand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be51a227-2d8a-4652-98cf-ed9eab969905",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "x = np.arange(len(df_compare_brand))\n",
    "w = 0.35\n",
    "\n",
    "plt.bar(x - w/2, df_compare_brand[\"MAE_mean_global\"], w, label=\"Global\")\n",
    "plt.bar(x + w/2, df_compare_brand[\"MAE_mean_brand\"],  w, label=\"Brand-specific\")\n",
    "plt.xticks(x, df_compare_brand[\"brand\"], rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"MAE (GBP)\")\n",
    "plt.title(\"Global vs Brand-specific (MAE)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.bar(df_compare_brand[\"brand\"], df_compare_brand[\"delta_MAE\"])\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Δ MAE (brand - global)\")\n",
    "plt.title(\"Effect of brand specialization (negative = MAE improvement)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfbc8477-2a21-4d4c-8612-c40b036d15db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 10.2.3 Brand-Model comparison (Global vs Pair-specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7eb4e5e8-1397-4f80-9873-87eab1416872",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Frequent (brand, model) pairs only (avoid conclusions from tiny segments)\n",
    "pair_counts = (\n",
    "    X_train.groupby([brand_col, model_col])\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "MIN_PAIR_SAMPLES = 80  # no overfitting on low sample sizes\n",
    "\n",
    "candidate_pairs = pair_counts[pair_counts >= MIN_PAIR_SAMPLES]\n",
    "\n",
    "print(f\"Number of candidate pairs (n >= {MIN_PAIR_SAMPLES}): {len(candidate_pairs)}\")\n",
    "\n",
    "# Show the most frequent pairs for context (readable table with names)\n",
    "display(candidate_pairs.head(500).reset_index(name=\"count\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99f681f4-b235-4073-ad5b-a2a62fca3c41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def eval_global_by_pair(pipe_template, X, y, brand_col, model_col, pairs, splits):\n",
    "    \"\"\"\n",
    "    Global model evaluation per (brand, model):\n",
    "    - Fit once per fold on ALL cars.\n",
    "    - Score only on validation rows for each selected pair.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(splits, start=1):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        pipe = clone(pipe_template)\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        y_pred = pipe.predict(X_va)\n",
    "\n",
    "        for (b, m) in pairs:\n",
    "            mask = (X_va[brand_col] == b) & (X_va[model_col] == m)\n",
    "            n = int(mask.sum())\n",
    "            if n == 0:\n",
    "                continue\n",
    "\n",
    "            mae, rmse = mae_rmse(y_va[mask], y_pred[mask])\n",
    "            rows.append({\"fold\": fold, \"brand\": b, \"model\": m, \"MAE\": mae, \"RMSE\": rmse, \"n\": n})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    summary = (\n",
    "        df.groupby([\"brand\", \"model\"])\n",
    "          .apply(lambda g: pd.Series({\n",
    "              \"MAE_mean\": g[\"MAE\"].mean(),\n",
    "              \"MAE_std\":  g[\"MAE\"].std(ddof=0),\n",
    "              \"RMSE_mean\": g[\"RMSE\"].mean(),\n",
    "              \"RMSE_std\":  g[\"RMSE\"].std(ddof=0),\n",
    "              \"n\": int(g[\"n\"].sum()),\n",
    "          }))\n",
    "          .reset_index()\n",
    "    )\n",
    "    return summary\n",
    "\n",
    "\n",
    "def eval_pair_specific(pipe_template, X, y, brand_col, model_col, pairs, splits, min_train_per_fold=40):\n",
    "    \"\"\"\n",
    "    Pair-specific models:\n",
    "    - For each fold and (brand, model): fit the pipeline only on that segment's training rows.\n",
    "    - Evaluate only on that segment's validation rows.\n",
    "\n",
    "    The min_train_per_fold guard is necessary because some folds can have too few samples\n",
    "    even if the pair is frequent overall.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(splits, start=1):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        for (b, m) in pairs:\n",
    "            tr_mask = (X_tr[brand_col] == b) & (X_tr[model_col] == m)\n",
    "            va_mask = (X_va[brand_col] == b) & (X_va[model_col] == m)\n",
    "\n",
    "            n_tr = int(tr_mask.sum())\n",
    "            n_va = int(va_mask.sum())\n",
    "\n",
    "            if n_va == 0 or n_tr < min_train_per_fold:\n",
    "                continue\n",
    "\n",
    "            pipe = clone(pipe_template)\n",
    "            pipe.fit(X_tr[tr_mask], y_tr[tr_mask])\n",
    "            y_pred = pipe.predict(X_va[va_mask])\n",
    "\n",
    "            mae, rmse = mae_rmse(y_va[va_mask], y_pred)\n",
    "            rows.append({\"fold\": fold, \"brand\": b, \"model\": m, \"MAE\": mae, \"RMSE\": rmse, \"n\": n_va})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    summary = (\n",
    "        df.groupby([\"brand\", \"model\"])\n",
    "          .apply(lambda g: pd.Series({\n",
    "              \"MAE_mean\": g[\"MAE\"].mean(),\n",
    "              \"MAE_std\":  g[\"MAE\"].std(ddof=0),\n",
    "              \"RMSE_mean\": g[\"RMSE\"].mean(),\n",
    "              \"RMSE_std\":  g[\"RMSE\"].std(ddof=0),\n",
    "              \"n\": int(g[\"n\"].sum()),\n",
    "          }))\n",
    "          .reset_index()\n",
    "    )\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d7b05c3-b398-4752-a3ff-aef4ace2cb6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pairs_list = list(candidate_pairs.index)  # list of (brand, model) tuples\n",
    "\n",
    "df_global_pair = eval_global_by_pair(\n",
    "    pipe_template, X_train, y_train, brand_col, model_col, pairs_list, splits\n",
    ").rename(columns={\n",
    "    \"MAE_mean\": \"MAE_mean_global\", \"MAE_std\": \"MAE_std_global\",\n",
    "    \"RMSE_mean\": \"RMSE_mean_global\", \"RMSE_std\": \"RMSE_std_global\",\n",
    "    \"n\": \"n_global\"\n",
    "})\n",
    "\n",
    "df_pair_spec = eval_pair_specific(\n",
    "    pipe_template, X_train, y_train, brand_col, model_col, pairs_list, splits, min_train_per_fold=40\n",
    ").rename(columns={\n",
    "    \"MAE_mean\": \"MAE_mean_pair\", \"MAE_std\": \"MAE_std_pair\",\n",
    "    \"RMSE_mean\": \"RMSE_mean_pair\", \"RMSE_std\": \"RMSE_std_pair\",\n",
    "    \"n\": \"n_pair\"\n",
    "})\n",
    "\n",
    "df_compare_pair = df_global_pair.merge(df_pair_spec, on=[\"brand\", \"model\"], how=\"inner\")\n",
    "df_compare_pair[\"delta_MAE\"] = df_compare_pair[\"MAE_mean_pair\"] - df_compare_pair[\"MAE_mean_global\"]\n",
    "df_compare_pair[\"delta_RMSE\"] = df_compare_pair[\"RMSE_mean_pair\"] - df_compare_pair[\"RMSE_mean_global\"]\n",
    "\n",
    "df_compare_pair = df_compare_pair.sort_values(\"delta_MAE\")\n",
    "\n",
    "# Full results (all frequent pairs) are here:\n",
    "display(df_compare_pair)\n",
    "\n",
    "# For the report: show the most improved + most harmed (readable subset)\n",
    "display_cols = [\"brand\", \"model\", \"n_global\", \"MAE_mean_global\", \"MAE_mean_pair\", \"delta_MAE\",\n",
    "                \"RMSE_mean_global\", \"RMSE_mean_pair\", \"delta_RMSE\"]\n",
    "\n",
    "print(\"Top 15 improvements (most negative ΔMAE):\")\n",
    "display(df_compare_pair[display_cols].head(15).round(1))\n",
    "\n",
    "print(\"Top 15 degradations (most positive ΔMAE):\")\n",
    "display(df_compare_pair[display_cols].tail(15).round(1))\n",
    "\n",
    "# Plots (same as before): ΔMAE bar plot for stable segments + scatter vs size\n",
    "MIN_PLOT_SAMPLES = 100\n",
    "df_plot = df_compare_pair[df_compare_pair[\"n_global\"] >= MIN_PLOT_SAMPLES].copy()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "x = np.arange(len(df_plot))\n",
    "plt.bar(x, df_plot[\"delta_MAE\"])\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.xticks(\n",
    "    x,\n",
    "    [f\"{b} {m}\" for b, m in zip(df_plot[\"brand\"], df_plot[\"model\"])],\n",
    "    rotation=90, ha=\"right\"\n",
    ")\n",
    "plt.ylabel(\"Δ MAE (pair - global)\")\n",
    "plt.title(\"Effect of (brand, model) specialization (negative = improvement)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(df_compare_pair[\"n_global\"], df_compare_pair[\"delta_MAE\"])\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"Number of samples per (brand, model) (out-of-fold counted)\")\n",
    "plt.ylabel(\"Δ MAE (pair - global)\")\n",
    "plt.title(\"ΔMAE vs segment size\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Open_End_Section_SHAP",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
